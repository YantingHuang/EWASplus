{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/CpGPython/code/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin,tpe,hp, STATUS_OK,Trials \n",
    "import deep_network_estimator as dne\n",
    "from sklearn.model_selection import cross_validate\n",
    "import math\n",
    "from sklearn.externals import joblib\n",
    "import Logger\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'deep_network_estimator' from '/home/ec2-user/CpGPython/code/deep_network_estimator.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(dne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_opt_score(estimator):\n",
    "    results = cross_validate(estimator,train_x,train_label,scoring=scoring,cv=cv,return_train_score=False,fit_params={'sample_weight':sample_weights_train})\n",
    "    if 'f1_macro' in scoring:\n",
    "        score = results['test_f1_macro'].mean()\n",
    "    elif 'f1' in  scoring:\n",
    "        score = results['test_f1'].mean()\n",
    "    if math.isnan(score) or math.isinf(score):\n",
    "        score = - np.Infinity\n",
    "    return score\n",
    "    \n",
    "def dnn_loss(params):\n",
    "    global estimators\n",
    "    dnn_estimator = dne.tensor_DNN(**params)\n",
    "    score = cal_opt_score(dnn_estimator)\n",
    "    estimators.extend([dnn_estimator])   \n",
    "    return {'loss':-score,'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_param = {'learning_rate':hp.choice('learning_rate',[0.1]),'max_depth': 3+hp.randint('max_depth',15),'n_estimators':500+hp.randint('n_estimators',3000),'reg_lambda': hp.uniform('reg_lambda',1,100),'gamma': hp.uniform('gamma',1,30)}\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Logistic Regression')\n",
    "parser.add_argument('-f',required=False,default='normal',help='feature set',dest='features',metavar='normal/autoencoder')\n",
    "parser.add_argument('-i',required=False,default=30,help='max iteration',dest='maxiter',metavar='30',type=int)\n",
    "parser.add_argument('-c',required=False,default=3,help='cv number',dest='cv',metavar='3',type=int)\n",
    "args = parser.parse_args()\n",
    "feature_dataset = args.features\n",
    "cv = args.cv\n",
    "max_iter = args.maxiter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_dataset = 'autoencoder'\n",
    "cv = 2\n",
    "max_iter = 2\n",
    "home='/home/ec2-user/CpGPython/'\n",
    "log_dir = home+'logs/'\n",
    "model_dir = home+'models/'\n",
    "logger = Logger.Logger(log_dir,False).get_logger()\n",
    "if feature_dataset == 'normal':\n",
    "##features selecetd by traditional methods\n",
    "    with pd.HDFStore(home+'data/selected_features','r') as h5s:\n",
    "        train_x =h5s['train_x'] \n",
    "        train_label = h5s['train_label'] \n",
    "        test_x = h5s['test_x'] \n",
    "        test_label = h5s['test_label']   \n",
    "        sample_weights_train = h5s['sample_weights_train'] \n",
    "        sample_weights_test = h5s['sample_weights_test'] \n",
    "    logger.info('Features used in training are from traditional feature selection')\n",
    "##features selected by sparse autoencoder\n",
    "elif feature_dataset == 'autoencoder':\n",
    "    with pd.HDFStore(home+'data/new_features','r') as h5s:\n",
    "        train_x =h5s['train_x'] \n",
    "        train_label = h5s['train_label'] \n",
    "        test_x = h5s['test_x'] \n",
    "        test_label = h5s['test_label']\n",
    "        sample_weights_train = h5s['sample_weights_train'] \n",
    "        sample_weights_test = h5s['sample_weights_test']\n",
    "    logger.info('Features used in training are from sparse autoencoder')\n",
    "train_x = pd.DataFrame(train_x)\n",
    "train_label = pd.Series(train_label)\n",
    "sample_weights_train = pd.Series(sample_weights_train)\n",
    "\n",
    "labels = train_label.unique()\n",
    "class_num = len(labels)\n",
    "feature_num = train_x.shape[1]\n",
    "dnn_param = {'batch_normalization': hp.choice('batch_normalization',[True]),\n",
    "             'l2_reg': hp.uniform('l2_reg',0.001,0.05),                            \n",
    "             'drop_out':hp.uniform('drop_out',0.1,0.5),\n",
    "             #'weight_factor':hp.uniform('weight_factor',1,2),\n",
    "             'steps':200+hp.randint('steps',2000),\n",
    "             'batch_size':hp.choice('batch_size',[30]),\n",
    "             'scoring':hp.choice('scoring',['precision']),\n",
    "             'n_classes':hp.choice('n_classes',[class_num]),\n",
    "             'hidden_layers':hp.choice('hidden_layers',[[int(feature_num*5),int(feature_num*3),int(feature_num*1)],[int(feature_num*4),int(feature_num*3),int(feature_num*2),int(feature_num*1)],[int(feature_num*3),int(feature_num*2.5),int(feature_num*2),int(feature_num*1.5),int(feature_num*1)],[int(feature_num*6),int(feature_num*3)]])\n",
    "             }\n",
    "\n",
    "if class_num <= 2:\n",
    "    scoring = ['precision','recall','f1','roc_auc','neg_log_loss']\n",
    "else:\n",
    "    scoring = ['precision_macro','recall_macro','f1_macro','neg_log_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:187\", shape=(?,), dtype=float64)\n",
      "Tensor(\"IteratorGetNext:187\", shape=(?,), dtype=float64)\n",
      "Tensor(\"IteratorGetNext:187\", shape=(?,), dtype=float64)\n",
      "Tensor(\"IteratorGetNext:187\", shape=(?,), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/CpGPython/models/tensor_DNN.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = Trials()\n",
    "estimators = []\n",
    "best = fmin(dnn_loss,dnn_param,algo=tpe.suggest,max_evals=max_iter,trials=trial)\n",
    "best_ix = np.argmin(trial.losses())\n",
    "best_estimator = estimators[best_ix]\n",
    "best_params = best_estimator.get_params() \n",
    "joblib.dump(best_params,model_dir+'tensor_DNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command_line = '{}code/HyperoptModels/run-opts.sh {} {} {}'.format(home,feature_dataset,max_iter,cv)\n",
    "args = shlex.split(command_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call([home+'code/HyperoptModels/run-opts.sh',str(feature_dataset),str(max_iter),str(cv)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess,shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_dataset = 'normal'\n",
    "cv = 3\n",
    "max_iter = 10\n",
    "home='/home/ec2-user/CpGPython/'\n",
    "log_dir = home+'logs/'\n",
    "model_dir = home+'models/'\n",
    "logger = Logger.Logger(log_dir,False).get_logger()\n",
    "if feature_dataset == 'normal':\n",
    "##features selecetd by traditional methods\n",
    "    with pd.HDFStore(home+'data/selected_features','r') as h5s:\n",
    "        train_x =h5s['train_x'] \n",
    "        train_label = h5s['train_label'] \n",
    "        test_x = h5s['test_x'] \n",
    "        test_label = h5s['test_label']   \n",
    "        sample_weights_train = h5s['sample_weights_train'] \n",
    "        sample_weights_test = h5s['sample_weights_test'] \n",
    "    logger.info('Features used in training are from traditional feature selection')\n",
    "##features selected by sparse autoencoder\n",
    "elif feature_dataset == 'autoencoder':\n",
    "    with pd.HDFStore(home+'data/new_features','r') as h5s:\n",
    "        train_x =h5s['train_x'] \n",
    "        train_label = h5s['train_label'] \n",
    "        test_x = h5s['test_x'] \n",
    "        test_label = h5s['test_label']\n",
    "        sample_weights_train = h5s['sample_weights_train'] \n",
    "        sample_weights_test = h5s['sample_weights_test']\n",
    "    logger.info('Features used in training are from sparse autoencoder')\n",
    "train_x = pd.DataFrame(train_x)\n",
    "train_label = pd.Series(train_label)\n",
    "sample_weights_train = pd.Series(sample_weights_train)\n",
    "\n",
    "labels = train_label.unique()\n",
    "class_num = len(labels)\n",
    "l_param = {'C': hp.uniform('C',0.05,10)}\n",
    "if class_num <= 2:\n",
    "    scoring = ['precision','recall','f1','roc_auc','neg_log_loss']\n",
    "else:\n",
    "    scoring = ['precision_macro','recall_macro','f1_macro','neg_log_loss']\n",
    "    l_param['solver'] = hp.choice('solver',['lbfgs'])\n",
    "    l_param['multi_class'] = hp.choice('multi_class',['multinomial'])\n",
    "    print(l_param)\n",
    "trial = Trials()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/CpGPython/models/LogisticRegression.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 10\n",
    "best = fmin(logistic_loss,l_param,algo=tpe.suggest,max_evals=max_iter,trials=trial) \n",
    "joblib.dump(best,model_dir+'LogisticRegression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = joblib.load(model_dir+'LogisticRegression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 6.383497398013961}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/anaconda3/envs/py3.6/bin/python'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shlex, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods=['xgbooster']\n",
    "feature_set = 'normal'\n",
    "max_iter = 3\n",
    "cv = 2\n",
    "args={}\n",
    "for method in methods:\n",
    "    command_line = 'python {}code/HyperoptModels/{}_hyperopt.py -f {} -i {} -c {}'.format(home,method,feature_set,max_iter,cv)\n",
    "    args[method] = shlex.split(command_line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbooster': ['python',\n",
       "  '/home/ec2-user/CpGPython/code/HyperoptModels/xgbooster_hyperopt.py',\n",
       "  '-f',\n",
       "  'normal',\n",
       "  '-i',\n",
       "  '3',\n",
       "  '-c',\n",
       "  '2']}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processes = {}\n",
    "for method,arg in args.items():\n",
    "    process = subprocess.Popen(arg)\n",
    "    outs, errs = p.communicate()\n",
    "    processes[method] = process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = joblib.load(model_dir+'tensor_DNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from HyperoptModels import parallel_ensemble as pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "methods=['LogisticRegression','RandomForestClassifier','SVC','xgbooster','tensor_DNN']\n",
    "es = pe.Ensemble(methods=methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 8.008342251635575, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 9, 'min_child_weight': 1, 'missing': None, 'n_estimators': 624, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 23.967889631668946, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 1}\n",
      "Tensor(\"IteratorGetNext:187\", shape=(?,), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ensemble(home='/home/ec2-user/CpGPython/',\n",
       "     methods=['LogisticRegression', 'RandomForestClassifier', 'SVC', 'xgbooster', 'tensor_DNN'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.fit(train_x,train_label,sample_weights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = es.score(test_x,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26567417361647433,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

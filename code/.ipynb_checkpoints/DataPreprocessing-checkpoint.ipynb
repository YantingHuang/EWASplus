{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Oct 31 19:51:52 2017\n",
    "\n",
    "@author: Xiaobo\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import utils \n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/CpGPython/code/')\n",
    "import re\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "def nearest_tss(tss,sites_df):\n",
    "    merged = pd.merge(sites_df,tss,how='outer',on=['chr','coordinate'])\n",
    "    merged.sort_values(['chr','coordinate'],inplace=True)\n",
    "    merged.rename(columns={'strand':'before_tss'},inplace=True)\n",
    "    merged.ix[merged['before_tss'].isnull()==False, 'before_tss'] = merged.ix[merged['before_tss'].isnull()==False,'coordinate']\n",
    "    merged['after_tss'] = merged['before_tss']\n",
    "    merged['before_tss'].fillna(method='ffill', inplace=True)\n",
    "    merged['after_tss'].fillna(method='bfill',inplace=True)\n",
    "    merged['dist_to_before_tss'] = np.abs(merged['coordinate']-merged['before_tss'])\n",
    "    merged['dist_to_after_tss'] = np.abs(merged['coordinate']-merged['after_tss'])\n",
    "    merged['tss'] = None\n",
    "    before_ix = (merged['dist_to_before_tss'] < merged['dist_to_after_tss']) | (merged['dist_to_after_tss'].isnull())\n",
    "    merged.ix[before_ix,'tss'] = merged.ix[before_ix,'before_tss']\n",
    "    after_ix = (merged['dist_to_before_tss'] >= merged['dist_to_after_tss']) | (merged['dist_to_before_tss'].isnull())\n",
    "    merged.ix[after_ix,'tss'] = merged.ix[after_ix,'after_tss']\n",
    "    merged['dist_to_nearest_tss'] = np.abs(merged['coordinate']-merged['tss']) \n",
    "    merged.dropna(axis=0,subset=['id'],inplace=True)\n",
    "    return merged\n",
    "#-----------------------------------------------------------------------    \n",
    "def sampling(x,control,rate=100):\n",
    "    index = x.index[0]\n",
    "    bin_num = x['bin'][index]\n",
    "    chr_num = x['chr'][index]\n",
    "    control1 = control.query('(bin == @bin_num) & (chr == @chr_num)')\n",
    "    sample_num = rate*len(x) if len(control1) >= rate*len(x) else len(control1)\n",
    "    sample = control1.sample(sample_num,replace=False)\n",
    "    return sample\n",
    "#-----------------------------------------------------------------------\n",
    "def rename_features(x):   #rename repetitive features\n",
    "    features = np.array(x.columns)\n",
    "    features_count = pd.Series(index=x.columns.unique())\n",
    "    features_count = features_count.fillna(int(0))\n",
    "    for i,name in enumerate(x.columns):\n",
    "        if features_count[name] == 0:\n",
    "            features_count[name] += 1\n",
    "        else:\n",
    "            features[i] = name+str(features_count[name])\n",
    "            features_count[name] += 1\n",
    "    x.columns = features\n",
    "    return \n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def convert_chr_to_num(data):\n",
    "    data['chr'].where(data['chr']!='X','23',inplace=True)\n",
    "    data['chr'].where(data['chr']!='Y','24',inplace=True)\n",
    "    data['chr'].where(data['chr']!='M','25',inplace=True)\n",
    "    data['chr'] = data['chr'].astype('i8')\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "       \n",
    "dir='/home/ec2-user/CpGPython/'\n",
    "\n",
    "#ewas_columns = ['EWAS_ID', 'ID_REF', 'chr','position','Gene_symbol','group1_valid_size','group2_valid_size','group1_average','group2_average','T_statistics','T_Pvalue']\n",
    "#ewas = pd.read_csv(dir+'ewas/ewas_AD.txt',names=ewas_columns,header=None,sep='\\t').reset_index()\n",
    "ewas = pd.read_csv(dir+'ewas/ewas_web.csv',sep='$',header=None,skiprows=1,names=['ewas_id','id','chr','coordinate','gene',\n",
    "\t\t\t 'group1','group2','group1_beta','group2_beta',\n",
    "\t\t\t't-stats','pvalue'])\n",
    "\n",
    "ewas['group'] = 1  # if norm is in group 2\n",
    "ewas['group'][ewas['group1'].apply(lambda x: 'Normal' in x)] = -1 #if norm is in group1\n",
    "ewas['adj-t-statistics'] = ewas['group']*ewas['t-stats']\n",
    "ewas.drop('group',axis=1,inplace=True)\n",
    "     \n",
    "#ewas = ewas[[ 'ID_REF','chr','position','T_statistics']]\n",
    "#ewas.rename({'position':'coordinate', 'ID_REF':'id'},inplace=True,axis=1)\n",
    "ewas['label'] = 1     \n",
    "ewas['label'][ewas['adj-t-statistics']<0] = -1\n",
    "ewas['chr'] = ewas['chr'].astype('str')\n",
    "ewas = ewas[['id','chr','coordinate','label']]\n",
    "\n",
    "control = pd.read_csv(dir+'sites.txt',sep=\"\\s+\",header=0)\n",
    "control.rename(columns={'coordinates':'coordinate'},inplace=True)\n",
    "control.dropna(axis=0,inplace=True)\n",
    "control = control.reset_index()\n",
    "control.sort_values(['chr','coordinate'],inplace=True)\n",
    "ewas_all = pd.read_csv(dir+'ewas/ewas_AD.txt',usecols=[2,3],names=['chr','coordinate'],sep='\\t')\n",
    "ewas_all.sort_values(['chr','coordinate'],inplace=True)\n",
    "ewas_all.drop_duplicates(inplace=True)\n",
    "overlaps_index = pd.merge(control,ewas_all,on=['chr','coordinate'],how='inner')['index']\n",
    "control.set_index('index',inplace=True)\n",
    "control.drop(overlaps_index,inplace=True)\n",
    "\n",
    "positive = pd.read_csv(dir+'PosCpG_diff.csv',usecols=[0,1,2,3],names=['id','chr','coordinate','score'])\n",
    "positive['chr']=positive['chr'].astype('str')\n",
    "positive['label'] = 1\n",
    "positive['label'].where(positive['score']>0,-1,inplace=True)  ## if AD>control, positive and assign 1, otherwise assign 0\n",
    "positive.drop('score',axis=1,inplace=True)\n",
    "\n",
    "stg = pd.read_excel(dir+'superior_temporal_gyrus_sites.xlsx',usecols=[0,1,2,3,13,14,15],names=['id','chr','start','end','state','pvalue','qvalue'],\n",
    "                    skiprows=3,header=None) #superior temporal gyrus dataset\n",
    "stg_pos = stg.query('state==\"Hyper\"')\n",
    "stg_neg = stg.query('state==\"Hypo\"')\n",
    "stg_pos.sort_values(['pvalue'],inplace=True)\n",
    "stg_neg.sort_values(['pvalue'],inplace=True)\n",
    "stg_positive = stg_pos.head(int(stg_pos.shape[0]*0.1))\n",
    "stg_positive['label'] = 1\n",
    "stg_negative = stg_neg.head(int(stg_neg.shape[0]*0.1))\n",
    "stg_negative['label'] = -1\n",
    "stg_control = pd.concat([stg_pos.tail(int(stg_pos.shape[0]*0.1)),stg_neg.tail(int(stg_neg.shape[0]*0.1))],ignore_index=True)\n",
    "stg_control['label'] = 0\n",
    "stg_control['coordinate'] = ((stg_control['start']+stg_control['end'])/2).astype('i8')\n",
    "stg_diff = pd.concat([stg_positive,stg_negative],ignore_index=True)\n",
    "stg_diff['coordinate'] = ((stg_diff['start']+stg_diff['end'])/2).astype('i8')\n",
    "       \n",
    "cols=['chr', 'coordinates','strand']\n",
    "tss =  pd.read_csv(dir+'tss.txt',sep='\\s+',header=None,names=cols,skiprows=1)\n",
    "tss['chr'] = tss['chr'].str[3:]\n",
    "tss.rename(columns={'coordinates':'coordinate'},inplace=True)\n",
    "\n",
    "ewas = ewas.sort_values(['chr','coordinate'])\n",
    "control = control.sort_values(['chr','coordinate'])\n",
    "positive = positive.sort_values(['chr','coordinate'])\n",
    "\n",
    "tss = tss.sort_values(['chr','coordinate'])\n",
    "stg_diff.sort_values(['chr','coordinate'],inplace=True)\n",
    "stg_control.sort_values(['chr','coordinate'],inplace=True)\n",
    "stg_diff['chr'] = stg_diff['chr'].apply(lambda x: x[3:])\n",
    "stg_control['chr'] = stg_control['chr'].apply(lambda x: x[3:])\n",
    "\n",
    "ewas_tss = nearest_tss(tss,ewas)\n",
    "ewas_tss = ewas_tss[ewas_tss['chr'].notnull()]\n",
    "ewas_tss = convert_chr_to_num(ewas_tss)\n",
    "\n",
    "positive_tss = nearest_tss(tss,positive)\n",
    "positive_tss['chr'] = positive_tss['chr'].astype('i8')\n",
    "\n",
    "stg_diff_tss = nearest_tss(tss,stg_diff)\n",
    "stg_control_tss = nearest_tss(tss,stg_control)\n",
    "stg_diff_tss = convert_chr_to_num(stg_diff_tss)\n",
    "stg_control_tss = convert_chr_to_num(stg_control_tss)\n",
    "\n",
    "\n",
    "\n",
    "overlap_tss = pd.merge(positive_tss,ewas_tss,on=['chr','coordinate'],how='left')\n",
    "missing_ix = overlap_tss[overlap_tss.isnull().sum(axis=1)>0].index\n",
    "missings = overlap_tss.ix[missing_ix,:].dropna(axis=1)\n",
    "missings.columns = [x if '_x' not in x  else x[:len(x)-2] for x in missings.columns]\n",
    "ewas_tss = ewas_tss.append(missings,ignore_index=True)\n",
    "ewas_tss.sort_values(['chr','coordinate'],inplace=True)\n",
    " \n",
    "control_tss = nearest_tss(tss, control)\n",
    "control_tss = control_tss[control_tss['chr'].notnull()]\n",
    "control_tss = convert_chr_to_num(control_tss)\n",
    "ewas_tss['bin'],boundaries = pd.qcut(ewas_tss['dist_to_nearest_tss'],10,retbins=True,labels=np.arange(10))\n",
    "\n",
    "boundaries[0]= -np.Inf\n",
    "boundaries[-1] = np.Inf\n",
    "\n",
    "control_tss['bin'] = pd.cut(control_tss['dist_to_nearest_tss'],boundaries,labels=np.arange(10))  \n",
    "control_samples = ewas_tss.groupby(['chr','bin']).apply(lambda x: sampling(x,control_tss))\n",
    "control_samples.sort_values(['chr','coordinate'],inplace=True)\n",
    "ewas_tss.sort_values(['chr','coordinate'],inplace=True)\n",
    "ewas_tss['start'] = (ewas_tss['coordinate']/200).apply(lambda x: int(np.ceil(x-1))*200+1)\n",
    "control_samples['start'] = (control_samples['coordinate']/200).apply(lambda x: int(np.ceil(x-1))*200+1)\n",
    "\n",
    "stg_diff_tss['start'] = (stg_diff_tss['coordinate']/200).apply(lambda x: int(np.ceil(x-1))*200+1)\n",
    "stg_control_tss['start'] = (stg_control_tss['coordinate']/200).apply(lambda x: int(np.ceil(x-1))*200+1)\n",
    "#-----------------------\n",
    "#load feature coordinates\n",
    "#-------------\n",
    "wincols=['chr','start','end']\n",
    "feature_wins = pd.read_csv(dir+'wins.txt',sep='\\s+',usecols=[0,1,2],header=None,names=wincols,skiprows=1)\n",
    "feature_wins.reset_index(inplace=True)\n",
    "feature_wins['index'] = feature_wins['index']+1\n",
    "kept_chr = []\n",
    "for i in np.arange(1,23):\n",
    "    kept_chr.extend(['chr'+str(i)])\n",
    "kept_chr.extend(['chrX','chrY'])\n",
    "\n",
    "feature_wins = feature_wins.query('chr in @kept_chr')\n",
    "feature_wins['chr'] = feature_wins['chr'].apply(lambda x: x[3:])\n",
    "feature_wins = convert_chr_to_num(feature_wins)   \n",
    "feature_wins.sort_values(['chr','start'],inplace=True)\n",
    "\n",
    "#-----------------------------------\n",
    "#Merge feature coordinates with positive/negative sites\n",
    "#-----------------------------------\n",
    "ewas_bin = pd.merge(ewas_tss,feature_wins, on=['chr','start'],how='left')\n",
    "ewas_bin.rename(columns={'index':'winid'},inplace=True)\n",
    "control_bin = pd.merge(control_samples,feature_wins, on =['chr','start'],how='left')\n",
    "control_bin.rename(columns={'index':'winid'},inplace=True)\n",
    "\n",
    "stg_diff_bin = pd.merge(stg_diff_tss,feature_wins,on=['chr','start'],how='left')\n",
    "stg_diff_bin.rename(columns={'index':'winid'},inplace=True)\n",
    "stg_control_bin = pd.merge(stg_control_tss,feature_wins,on=['chr','start'],how='left')\n",
    "stg_control_bin.rename(columns={'index':'winid'},inplace=True)\n",
    "stg_diff_bin = stg_diff_bin.dropna(axis=0).reset_index().drop(['index'],axis=1)\n",
    "stg_control_bin = stg_control_bin.dropna(axis=0).reset_index().drop(['index'],axis=1)\n",
    "#--------------------\n",
    "#export positive/negative winid for R to load and find corresponding features for export\n",
    "#--------------------\n",
    "\n",
    "ewas_bin['winid'].to_csv(dir+'pos_winid.csv',index=False)\n",
    "control_bin['winid'].to_csv(dir+'neg_winid.csv',index=False)\n",
    "\n",
    "stg_diff_bin['winid'].to_csv(dir+'pos_winid.csv',index=False)\n",
    "stg_control_bin['winid'].to_csv(dir+'neg_winid.csv',index=False)\n",
    "\n",
    "#import features of all positive sites\n",
    "feature_dir = dir+'data/features/'\n",
    "files = os.listdir(feature_dir)\n",
    "pattern = '.*Pos.csv$'\n",
    "reg = re.compile(pattern)\n",
    "files = [name for name in files if len(reg.findall(name))>0]\n",
    "\n",
    "\n",
    "for file in files:    \n",
    "    feature = pd.read_csv(feature_dir+file)\n",
    "    print(len(feature.columns))\n",
    "#    ewas_bin = pd.concat([ewas_bin,feature],axis=1)\n",
    "    stg_diff_bin = pd.concat([stg_diff_bin,feature],axis=1)\n",
    "    \n",
    "rename_features(ewas_bin)\n",
    "rename_features(stg_diff_bin)\n",
    "\n",
    "ewas_bin['bin'] = ewas_bin['bin'].astype('int64')\n",
    "h5s = pd.HDFStore(dir+'/data/ewas_features','w')\n",
    "h5s['ewas_features'] = ewas_bin\n",
    "h5s.close()\n",
    "with pd.HDFStore(dir+'/data/stg_features','w') as h5s:\n",
    "    h5s['stg_features'] = stg_diff_bin\n",
    "\n",
    "ewas_bin.drop(ewas_bin.columns[[0,4,5,6,7,8,10,11,12,13]],inplace=True,axis=1)\n",
    "stg_diff_bin.drop(stg_diff_bin.columns[[0,1,2,3,4,5,6,8,9,10,11,12,13,15,16]],inplace=True,axis=1)               \n",
    "#import features of all negative sites\n",
    "\n",
    "files = os.listdir(feature_dir)\n",
    "pattern = '.*neg.csv$'\n",
    "reg = re.compile(pattern)\n",
    "files = [name for name in files if len(reg.findall(name))>0]\n",
    "# files = list(name for name in itertools.ifilter(lambda x: len(reg.findall())>0,files)) \n",
    "for file in files:    \n",
    "    feature = pd.read_csv(feature_dir+file)\n",
    "#    control_bin = pd.concat([control_bin,feature],axis=1)\n",
    "    stg_control_bin = pd.concat([stg_control_bin,feature],axis=1)\n",
    "    \n",
    "rename_features(control_bin)\n",
    "rename_features(stg_control_bin)\n",
    "\n",
    "control_bin['label'] = 0\n",
    "control_bin['bin'] = control_bin['bin'].astype('i8')\n",
    "h5s = pd.HDFStore(dir+'/data/negative_features','w')\n",
    "h5s['control_features'] = control_bin\n",
    "h5s.close()\n",
    "\n",
    "with pd.HDFStore(dir+'/data/negative_features','w') as h5s:\n",
    "    h5s['stg_control_features'] = stg_control_bin\n",
    "\n",
    "control_bin.drop(control_bin.columns[[0,3,4,5,6,7,9,10,11,12]],axis=1,inplace=True)\n",
    "stg_control_bin.drop(stg_control_bin.columns[[0,1,2,3,4,5,6,8,9,10,11,12,13,15,16]],axis=1,inplace=True)\n",
    "\n",
    "#--------------------\n",
    "#merge positive and negative data \n",
    "#---------------------\n",
    "\n",
    "all_features = pd.concat([ewas_bin,control_bin],ignore_index=True)\n",
    "stg_all_features = pd.concat([stg_diff_bin,stg_control_bin],ignore_index=True)\n",
    "h5s = pd.HDFStore(dir+'/data/all_features','w')\n",
    "h5s['all_features'] = all_features\n",
    "h5s.close()\n",
    "with pd.HDFStore(dir+'/data/all_features','w') as h5s:\n",
    "    h5s['all_features'] = stg_all_features\n",
    "       \n",
    "\n",
    "###############################################################################\n",
    "#############################################################################\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import utils \n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/CpGPython/code/')\n",
    "import re\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "def nearest_tss(tss,sites_df):\n",
    "    merged = pd.merge(sites_df,tss,how='outer',on=['chr','coordinate'])\n",
    "    merged.sort_values(['chr','coordinate'],inplace=True)\n",
    "    merged.rename(columns={'strand':'before_tss'},inplace=True)\n",
    "    merged.ix[merged['before_tss'].isnull()==False, 'before_tss'] = merged.ix[merged['before_tss'].isnull()==False,'coordinate']\n",
    "    merged['after_tss'] = merged['before_tss']\n",
    "    merged['before_tss'].fillna(method='ffill', inplace=True)\n",
    "    merged['after_tss'].fillna(method='bfill',inplace=True)\n",
    "    merged['dist_to_before_tss'] = np.abs(merged['coordinate']-merged['before_tss'])\n",
    "    merged['dist_to_after_tss'] = np.abs(merged['coordinate']-merged['after_tss'])\n",
    "    merged['tss'] = None\n",
    "    before_ix = (merged['dist_to_before_tss'] < merged['dist_to_after_tss']) | (merged['dist_to_after_tss'].isnull())\n",
    "    merged.ix[before_ix,'tss'] = merged.ix[before_ix,'before_tss']\n",
    "    after_ix = (merged['dist_to_before_tss'] >= merged['dist_to_after_tss']) | (merged['dist_to_before_tss'].isnull())\n",
    "    merged.ix[after_ix,'tss'] = merged.ix[after_ix,'after_tss']\n",
    "    merged['dist_to_nearest_tss'] = np.abs(merged['coordinate']-merged['tss']) \n",
    "    merged.dropna(axis=0,subset=['id'],inplace=True)\n",
    "    return merged\n",
    "#-----------------------------------------------------------------------    \n",
    "def sampling(x,control,rate=100):\n",
    "    index = x.index[0]\n",
    "    bin_num = x['bin'][index]\n",
    "    chr_num = x['chr'][index]\n",
    "    control1 = control.query('(bin == @bin_num) & (chr == @chr_num)')\n",
    "    sample_num = rate*len(x) if len(control1) >= rate*len(x) else len(control1)\n",
    "    sample = control1.sample(sample_num,replace=False)\n",
    "    return sample\n",
    "#-----------------------------------------------------------------------\n",
    "def rename_features(x):   #rename repetitive features\n",
    "    features = np.array(x.columns)\n",
    "    features_count = pd.Series(index=x.columns.unique())\n",
    "    features_count = features_count.fillna(int(0))\n",
    "    for i,name in enumerate(x.columns):\n",
    "        if features_count[name] == 0:\n",
    "            features_count[name] += 1\n",
    "        else:\n",
    "            features[i] = name+str(features_count[name])\n",
    "            features_count[name] += 1\n",
    "    x.columns = features\n",
    "    return \n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def convert_chr_to_num(data):\n",
    "    data['chr'].where(data['chr']!='X','23',inplace=True)\n",
    "    data['chr'].where(data['chr']!='Y','24',inplace=True)\n",
    "    data['chr'].where(data['chr']!='M','25',inplace=True)\n",
    "    data['chr'] = data['chr'].astype('i8')\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "       \n",
    "dir='/home/ec2-user/CpGPython/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/py35tf/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/py35tf/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/py35tf/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ec2-user/anaconda3/envs/py35tf/lib/python3.5/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "stg = pd.read_excel(dir+'superior_temporal_gyrus_sites.xlsx',usecols=[0,1,2,3,13,14,15],names=['id','chr','start','end','state','pvalue','qvalue'],\n",
    "                    skiprows=3,header=None) #superior temporal gyrus dataset\n",
    "stg_pos = stg.query('state==\"Hyper\"')\n",
    "stg_neg = stg.query('state==\"Hypo\"')\n",
    "stg_pos.sort_values(['pvalue'],inplace=True)\n",
    "stg_neg.sort_values(['pvalue'],inplace=True)\n",
    "stg_positive = stg_pos.head(int(stg_pos.shape[0]*0.1))\n",
    "stg_positive['label'] = 2\n",
    "stg_negative = stg_neg.head(int(stg_neg.shape[0]*0.1))\n",
    "stg_negative['label'] = 0\n",
    "stg_control = pd.concat([stg_pos.tail(int(stg_pos.shape[0]*0.1)),stg_neg.tail(int(stg_neg.shape[0]*0.1))],ignore_index=True)\n",
    "stg_control['label'] = 1\n",
    "stg_control['coordinate'] = ((stg_control['start']+stg_control['end'])/2).astype('i8')\n",
    "stg_diff = pd.concat([stg_positive,stg_negative],ignore_index=True)\n",
    "stg_diff['coordinate'] = ((stg_diff['start']+stg_diff['end'])/2).astype('i8')\n",
    "       \n",
    "cols=['chr', 'coordinates','strand']\n",
    "tss =  pd.read_csv(dir+'tss.txt',sep='\\s+',header=None,names=cols,skiprows=1)\n",
    "tss['chr'] = tss['chr'].str[3:]\n",
    "tss.rename(columns={'coordinates':'coordinate'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tss = tss.sort_values(['chr','coordinate'])\n",
    "stg_diff.sort_values(['chr','coordinate'],inplace=True)\n",
    "stg_control.sort_values(['chr','coordinate'],inplace=True)\n",
    "stg_diff['chr'] = stg_diff['chr'].apply(lambda x: x[3:])\n",
    "stg_control['chr'] = stg_control['chr'].apply(lambda x: x[3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/py35tf/lib/python3.5/site-packages/ipykernel/__main__.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "stg_diff_tss = nearest_tss(tss,stg_diff)\n",
    "stg_control_tss = nearest_tss(tss,stg_control)\n",
    "stg_diff_tss = convert_chr_to_num(stg_diff_tss)\n",
    "stg_control_tss = convert_chr_to_num(stg_control_tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stg_diff_tss['start'] = (stg_diff_tss['coordinate']/200).apply(lambda x: int(np.ceil(x-1))*200+1)\n",
    "stg_control_tss['start'] = (stg_control_tss['coordinate']/200).apply(lambda x: int(np.ceil(x-1))*200+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wincols=['chr','start','end']\n",
    "feature_wins = pd.read_csv(dir+'wins.txt',sep='\\s+',usecols=[0,1,2],header=None,names=wincols,skiprows=1)\n",
    "feature_wins.reset_index(inplace=True)\n",
    "feature_wins['index'] = feature_wins['index']+1\n",
    "kept_chr = []\n",
    "for i in np.arange(1,23):\n",
    "    kept_chr.extend(['chr'+str(i)])\n",
    "kept_chr.extend(['chrX','chrY'])\n",
    "\n",
    "feature_wins = feature_wins.query('chr in @kept_chr')\n",
    "feature_wins['chr'] = feature_wins['chr'].apply(lambda x: x[3:])\n",
    "feature_wins = convert_chr_to_num(feature_wins)   \n",
    "feature_wins.sort_values(['chr','start'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stg_diff_bin = pd.merge(stg_diff_tss,feature_wins,on=['chr','start'],how='left')\n",
    "stg_diff_bin.rename(columns={'index':'winid'},inplace=True)\n",
    "stg_control_bin = pd.merge(stg_control_tss,feature_wins,on=['chr','start'],how='left')\n",
    "stg_control_bin.rename(columns={'index':'winid'},inplace=True)\n",
    "stg_diff_bin = stg_diff_bin.dropna(axis=0).reset_index().drop(['index'],axis=1)\n",
    "stg_control_bin = stg_control_bin.dropna(axis=0).reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'chr', 'start', 'end', 'state', 'pvalue', 'qvalue', 'label',\n",
       "       'coordinate', 'before_tss', 'after_tss', 'dist_to_before_tss',\n",
       "       'dist_to_after_tss', 'tss', 'dist_to_nearest_tss'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stg_control_tss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "73\n",
      "303\n",
      "267\n",
      "80\n",
      "317\n",
      "735\n"
     ]
    }
   ],
   "source": [
    "feature_dir = dir+'data/features/'\n",
    "files = os.listdir(feature_dir)\n",
    "pattern = '.*Pos.csv$'\n",
    "reg = re.compile(pattern)\n",
    "files = [name for name in files if len(reg.findall(name))>0]\n",
    "\n",
    "\n",
    "for file in files:    \n",
    "    feature = pd.read_csv(feature_dir+file)\n",
    "    print(len(feature.columns))\n",
    "#    ewas_bin = pd.concat([ewas_bin,feature],axis=1)\n",
    "    stg_diff_bin = pd.concat([stg_diff_bin,feature],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rename_features(stg_diff_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(dir+'data/stg_features','w') as h5s:\n",
    "    h5s['stg_features'] = stg_diff_bin\n",
    "\n",
    "stg_diff_bin.drop(stg_diff_bin.columns[[0,1,2,3,4,5,6,8,9,10,11,12,13,15,16]],inplace=True,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir(feature_dir)\n",
    "pattern = '.*neg.csv$'\n",
    "reg = re.compile(pattern)\n",
    "files = [name for name in files if len(reg.findall(name))>0]\n",
    "# files = list(name for name in itertools.ifilter(lambda x: len(reg.findall())>0,files)) \n",
    "for file in files:    \n",
    "    feature = pd.read_csv(feature_dir+file)\n",
    "#    control_bin = pd.concat([control_bin,feature],axis=1)\n",
    "    stg_control_bin = pd.concat([stg_control_bin,feature],axis=1)\n",
    "    \n",
    "rename_features(stg_control_bin)\n",
    "\n",
    "with pd.HDFStore(dir+'data/negative_features','w') as h5s:\n",
    "    h5s['stg_control_features'] = stg_control_bin\n",
    "\n",
    "\n",
    "stg_control_bin.drop(stg_control_bin.columns[[0,1,2,3,4,5,6,8,9,10,11,12,13,15,16]],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#--------------------\n",
    "#merge positive and negative data \n",
    "#---------------------\n",
    "\n",
    "\n",
    "stg_all_features = pd.concat([stg_diff_bin,stg_control_bin],ignore_index=True)\n",
    "with pd.HDFStore(dir+'data/all_features','w') as h5s:\n",
    "    h5s['all_features'] = stg_all_features "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

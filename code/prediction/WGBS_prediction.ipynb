{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from common import commons\n",
    "home = commons.home\n",
    "sys.path.append('/home/ec2-user/anaconda3/lib/python3.6/site-packages')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models import ModelSelection as MS\n",
    "from models import Ensemble as es\n",
    "from models import xgbooster\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score,accuracy_score,f1_score,roc_curve,roc_auc_score,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import clone\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from importlib import reload\n",
    "from log import Logger\n",
    "from models import deep_network_estimator as dne\n",
    "from models import Ensemble_hyperopt as eh\n",
    "from hyperopt import fmin,tpe,hp, STATUS_OK,Trials\n",
    "from hyperopt_models import parallel_ensemble as pe\n",
    "from functools import reduce\n",
    "import itertools\n",
    "import prediction_commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_curves_cv(probs,label,methods,types='roc_curve'):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title(types)\n",
    "    plt.axis([0,1,0,1])\n",
    "    lw = 2\n",
    "    colors = ['r','b','g','k','c','m','y']\n",
    "    for method,color in zip(methods,colors[:len(methods)]):\n",
    "        if types == 'precision_recall_curve':       \n",
    "            precision,recall,threshold = precision_recall_curve(label,probs[method])\n",
    "            plt.plot(recall,precision,color,linewidth=2,label=method)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.plot([0, 1], [1, 0], color='navy', lw=lw, linestyle='--')\n",
    "        if types == 'roc_curve':\n",
    "            fpr,tpr, threshold = roc_curve(label,probs[method])\n",
    "            plt.plot(fpr,tpr,color,linewidth=2,label=method)\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('Recall')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "def get_estimators(methods,params,train_x,train_label):\n",
    "    ensemble = eh.Ensemble(methods,params)\n",
    "    ensemble.fit(train_x,train_label,sample_weight=sample_weight_train,max_iter=100)\n",
    "    return ensemble\n",
    "#-----------------------------------------------------------------------------\n",
    "def plot_curves(estimators,test_x,label,types='roc_curve'):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title(types)\n",
    "    plt.axis([0,1,0,1])\n",
    "    lw = 2\n",
    "    colors = ['r','b','g','k','c','m','y']\n",
    "    for color,estimator in zip(colors[:len(estimators)],estimators):\n",
    "        name = type(estimator).__name__\n",
    "        probs = np.array(estimator.predict_proba(test_x))[:,1]\n",
    "        if types == 'precision_recall_curve':       \n",
    "            precision,recall,threshold = precision_recall_curve(label,probs)\n",
    "            plt.plot(recall,precision,color,linewidth=2,label=name)\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.plot([0, 1], [1, 0], color='navy', lw=lw, linestyle='--')\n",
    "        if types == 'roc_curve':\n",
    "            fpr,tpr, threshold = roc_curve(label,probs)\n",
    "            plt.plot(fpr,tpr,color,linewidth=2,label=name)\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('Recall')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.legend(loc='best')\n",
    "#-----------------------------------------------------------------------------\n",
    "def learn_curve(model,train_x,train_label,cv=3,scoring='neg_log_loss'):\n",
    "    model_c = clone(model)\n",
    "    N,train_score,test_score = learning_curve(model_c, \n",
    "                                            train_x,train_label,cv=cv,train_sizes=np.linspace(0.5,1,5),\n",
    "                                            scoring=scoring)\n",
    "    \n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.title('{}'.format(type(model).__name__))\n",
    "    plt.plot(N,np.mean(train_score,1),color='blue', label='training score')\n",
    "    plt.plot(N,np.mean(test_score,1),color='red',label='validation score')\n",
    "    plt.xlabel('training sample')\n",
    "    plt.ylabel(scoring)\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()\n",
    "#-----------------------------------------------------------------------------    \n",
    "def error_analysis(estimator,test_x,label,types=['confusion_matrix']):\n",
    "    print('Error analysis of ',type(estimator).__name__)\n",
    "    predict = estimator.predict(test_x)\n",
    "    probs = np.array(estimator.predict_proba(test_x))[:,1]\n",
    "    class_num = len(label.unique())\n",
    "    if 'confusion_matrix' in types:\n",
    "        conf_mat = confusion_matrix(label,predict)\n",
    "        row_sums = conf_mat.sum(axis=1,keepdims=True)\n",
    "        norm_conf_mat = conf_mat/row_sums\n",
    "        np.fill_diagonal(norm_conf_mat,0)\n",
    "        plt.matshow(norm_conf_mat,cmap=plt.cm.gray)        \n",
    "    if 'precision_recall_curve' in types and class_num<=2:\n",
    "        precision,recall,threshold = precision_recall_curve(label,probs)\n",
    "        plot_curve(recall,precision,type(estimator).__name__,'precision_recall_curve')\n",
    "    if 'roc_curve' in types and class_num<=2:\n",
    "        fpr,tpr, threshold = roc_curve(label,probs)\n",
    "        plot_curve(fpr,tpr,type(estimator).__name__,'roc_curve')    \n",
    "    plt.show()\n",
    "#---------------------------------------------------------------------------    \n",
    "def plot_curve(score1,score2,label,types):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title(types)\n",
    "    plt.plot(score1,score2,linewidth=2,label=label)\n",
    "    plt.plot([0,1],[1,1],'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    lw = 2\n",
    "    if types == 'precision_recall_curve':        \n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.plot([0, 1], [1, 0], color='navy', lw=lw, linestyle='--')\n",
    "    if types == 'roc_curve':\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "#--------------------------------------------------------------------------\n",
    "def scores(y,predicts,pred_probs,average='macro'):\n",
    "    class_num = len(y.unique())\n",
    "    score_map = {}\n",
    "\n",
    "    if class_num <=2:\n",
    "        recall = recall_score(y,predicts)      \n",
    "        precision = precision_score(y,predicts)      \n",
    "        accuracy = accuracy_score(y,predicts)\n",
    "        f1 = f1_score(y,predicts)\n",
    "        auc = roc_auc_score(y,pred_probs)\n",
    "        score_map['auc'] = auc\n",
    "    else:\n",
    "        recall = recall_score(y,predicts,average=average)      \n",
    "        precision = precision_score(y,predicts,average=average)      \n",
    "        accuracy = accuracy_score(y,predicts)\n",
    "        f1 = f1_score(y,predicts,average=average)\n",
    "        \n",
    "    score_map['recall'] = recall\n",
    "    score_map['precision'] = precision\n",
    "    score_map['accuracy'] = accuracy\n",
    "    score_map['f1'] = f1\n",
    "    return score_map\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "def cross_val_ensemble(x,y,sample_weight,methods,params,fold=10, hyperopt=True,up_sampling=False):\n",
    "    skfolds = StratifiedKFold(n_splits=10,random_state=43)\n",
    "    results = []\n",
    "    model_combine_scores_cv = []\n",
    "    model_scores_cv = []\n",
    "    best_params_cv = []\n",
    "    cv_columns = ['label','ensemble']+methods\n",
    "    pred_probs_cv = pd.DataFrame(columns=cv_columns)\n",
    "    predicts_cv = pd.DataFrame(columns=cv_columns)\n",
    "    if not hyperopt:\n",
    "        search_methods = get_train_models(models=methods)\n",
    "    class_num = len(y.unique())\n",
    "    for train_index,test_index in skfolds.split(x,y):\n",
    "        train_fold = x.ix[train_index,:]\n",
    "        train_label = y[train_index]\n",
    "        sample_weight_train = sample_weight[train_index]\n",
    "        test_fold = x.ix[test_index,:]\n",
    "        test_label = y[test_index]\n",
    "        sample_weight_test = sample_weight[test_index]\n",
    "        if up_sampling:\n",
    "            train_fold,train_label,sample_weight_train = upsampling(train_fold,train_label,sample_weight_train,fold=9)\n",
    "            test_fold,test_label,sample_weight_test = downsampling(test_fold,test_label,sample_weight_test)\n",
    "        if not hyperopt:            \n",
    "            for param_l in params.values():\n",
    "                param = param_l[0]\n",
    "                if 'sample_weight' in param:\n",
    "                    param['sample_weight'] = [sample_weight_train,]\n",
    "            ensemble = es.Ensemble(methods=search_methods,params=params)\n",
    "            ensemble.fit(train_fold,train_label)            \n",
    "        else:\n",
    "            ensemble = eh.Ensemble(methods,params)\n",
    "            ensemble.fit(train_fold,train_label,sample_weight=sample_weight_train,max_iter=100)\n",
    "        score = ensemble.score(test_fold,test_label)\n",
    "        results.extend([score])\n",
    "        model_prob = ensemble.model_probs()\n",
    "        model_preds = ensemble.model_predicts() \n",
    "        ensemble_prob = ensemble.predict_proba(test_fold)\n",
    "        ensemble_pred = ensemble.predict(test_fold)\n",
    "        \n",
    "        temp_df = pd.DataFrame(columns=pred_probs_cv.columns)\n",
    "        for method,prob in model_prob.items():\n",
    "            temp_df[method] = prob[:,1]\n",
    "            temp_df[method] = temp_df[method].astype('f')\n",
    "        temp_df['ensemble'] = ensemble_prob[:,1]\n",
    "        temp_df['ensemble'] = temp_df['ensemble'].astype('f')\n",
    "        temp_df['label'] = test_label\n",
    "        temp_df['label'] = temp_df['label'].astype('i8')\n",
    "        pred_probs_cv = pred_probs_cv.append(temp_df,ignore_index=True)\n",
    "        \n",
    "        \n",
    "        temp_df = pd.DataFrame(columns=predicts_cv.columns)\n",
    "        for method,pred in model_preds.items():\n",
    "            temp_df[method] = pred\n",
    "            temp_df[method] = temp_df[method].astype('i8')\n",
    "        temp_df['ensemble'] = ensemble_pred\n",
    "        temp_df['ensemble'] = temp_df['ensemble'].astype('i8')\n",
    "        temp_df['label'] = test_label\n",
    "        temp_df['label'] = temp_df['label'].astype('i8')\n",
    "        predicts_cv = predicts_cv.append(temp_df,ignore_index=True)\n",
    "        \n",
    "        comb_results = methods_combination_results(methods,model_prob,test_label)\n",
    "        model_combine_scores_cv.extend([comb_results])\n",
    "        model_score = ensemble.get_model_scores()\n",
    "        model_scores_cv.extend([model_score.copy()])\n",
    "        best_params = ensemble.best_params()\n",
    "        best_params_cv.extend([best_params.copy()])\n",
    "        all_estimators = list(ensemble.best_estimators_.values())\n",
    "        all_estimators.extend([ensemble])\n",
    "        plot_curves(all_estimators,test_fold,test_label,types='roc_curve')\n",
    "        plot_curves(all_estimators,test_fold,test_label,types='precision_recall_curve')\n",
    "        del ensemble\n",
    "    if class_num == 2:\n",
    "        result_df = pd.DataFrame(results,columns=['logloss','f1','recall','precision','auc_score'])\n",
    "    else:\n",
    "        result_df = pd.DataFrame(results,columns=['logloss','f1','recall','precision'])\n",
    "    return result_df,model_combine_scores_cv,model_scores_cv,best_params_cv,pred_probs_cv,predicts_cv\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def soft_voting(model_probs):\n",
    "    pred_probs = reduce(lambda x,y: np.add(x,y), model_probs.values())/len(model_probs)\n",
    "    print(pred_probs)\n",
    "    predicts = np.argmax(pred_probs,axis=1)\n",
    "    return pred_probs,predicts    \n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "def get_search_params(methods=['LogisticRegression','RandomForestClassifier','SVC','MLPClassifier','xgbooster','tensor_DNN']):\n",
    "    params={}\n",
    "    feature_num = train_x.shape[1]\n",
    "    #class_weight = {0:1,1:30}\n",
    "    class_weight = None\n",
    "    l_param=[{'C':np.linspace(0.01, 20,20),'class_weight':[class_weight],'sample_weight':[sample_weights_train]}]\n",
    "    rf_param = [{'n_estimators':np.linspace(10,500,5,dtype='i8'),'max_depth':np.linspace(5,30,6,dtype='i8'),'min_samples_split': np.linspace(3,30,5,dtype='i8'),'min_samples_leaf': np.linspace(1,10,10,dtype='i8'),'class_weight':[class_weight],'sample_weight':[sample_weights_train]}]\n",
    "    svc_param = [{'C':np.linspace(0.01,0.2,5),'gamma':np.linspace(0.001,0.5,5),'class_weight':[class_weight],'sample_weight':[sample_weights_train]}]\n",
    "    mlp_param = [{'alpha':np.linspace(0.001,5,10),'max_iter':[3000],'hidden_layer_sizes':[(100,80,50,25,10),(200,120,80,40),(300,200,100),(400,200)]}]\n",
    "    xgb_param = [{'learning_rate':[0.1],'max_depth': np.linspace(3,21,6,dtype='i8'),'n_estimators':np.linspace(500,2000,5,dtype='i8'),'reg_lambda': np.linspace(1,50,10),'gamma':np.linspace(0.1,20,10),'class_weight':[class_weight],'sample_weight':[sample_weights_train],'search':['random',],'n_iter':[20] }]\n",
    "    dnn_param = [{'batch_normalization': [True],\n",
    "                 'l2_reg': np.linspace(0.01,5,5),                            \n",
    "                 'drop_out':np.linspace(0.1,0.8,4),\n",
    "                 'n_classes': [len(train_label.unique())],\n",
    "                 'hidden_layers': [[int(feature_num*5),int(feature_num*3),int(feature_num*1)],[int(feature_num*4),int(feature_num*3),int(feature_num*2),int(feature_num*1)],[int(feature_num*3),int(feature_num*2.5),int(feature_num*2),int(feature_num*1.5),int(feature_num*1)],[int(feature_num*6),int(feature_num*3)]],\n",
    "                 #'weight_factor':np.linspace(1,2,3),\n",
    "                 'steps':np.linspace(200,2000,10,dtype='i8'),\n",
    "                 'batch_size':[30],\n",
    "                 'scoring':['precision'],\n",
    "                 'sample_weight':[sample_weights_train],\n",
    "                 'search':['random',],\n",
    "                 'n_iter':[50]\n",
    "                 }]\n",
    "    if 'LogisticRegression' in methods:\n",
    "        params['LogisticRegression'] = l_param\n",
    "    if 'RandomForestClassifier' in methods:\n",
    "        params['RandomForestClassifier'] = rf_param\n",
    "    if 'SVC' in methods:\n",
    "        params['SVC'] = svc_param\n",
    "    if 'MLPClassifier' in methods:\n",
    "        params['MLPClassifier'] = mlp_param\n",
    "    if 'xgbooster' in methods:\n",
    "        params['xgbooster'] = xgb_param\n",
    "    if 'tensor_DNN' in methods:\n",
    "        params['tensor_DNN'] = dnn_param\n",
    "    return params\n",
    "#-----------------------------------------------------------------------------------\n",
    "def get_train_models(models=['LogisticRegression','RandomForestClassifier','SVC','MLPClassifier','xgbooster','tensor_DNN']):\n",
    "    methods = []\n",
    "    l = LogisticRegression()\n",
    "    rf = RandomForestClassifier()\n",
    "    svc = SVC()\n",
    "    xg = xgbooster.xgbooster()\n",
    "    mlp = MLPClassifier()\n",
    "    dnn = dne.tensor_DNN()\n",
    "    lsvc = LinearSVC()\n",
    "    if 'LogisticRegression' in models:\n",
    "        methods.extend([l])\n",
    "    if 'RandomForestClassifier' in models:\n",
    "        methods.extend([rf])\n",
    "    if 'SVC' in models:\n",
    "        methods.extend([svc])\n",
    "    if 'MLPClassifier' in models:\n",
    "        methods.extend([mlp])\n",
    "    if 'xgbooster' in models:\n",
    "        methods.extend([xg])\n",
    "    if 'tensor_DNN' in models:\n",
    "        methods.extend([dnn])\n",
    "    if 'LinearSVC' in models:\n",
    "        methods.extend([lsvc])\n",
    "    return methods\n",
    " #------------------------------------------------------------------------------\n",
    "\n",
    "def get_hyperopt_params(methods=['LogisticRegression','RandomForestClassifier','LinearSVC','SVC','xgbooster','tensor_DNN','MLPClassifier'],wtf_lo=1,wtf_hi=1):\n",
    "    weight_factor = hp.uniform('weight_factor',wtf_lo,wtf_hi)\n",
    "    weight_factor = hp.uniform('weight_factor',wtf_lo,wtf_hi)\n",
    "    params={}\n",
    "    l_param = {'C': hp.uniform('C',0.05,20),'weight_factor':weight_factor}\n",
    "    rf_param = {'n_estimators':100+hp.randint('n_estimators',900),'max_depth':5+hp.randint('max_depth',20), 'min_samples_split': 5+hp.randint('min_samples_split',15),'min_samples_leaf': 2+hp.randint('min_samples_leaf',4),'weight_factor':weight_factor}\n",
    "    svc_param = {'C': hp.uniform('C',0.005,1),'gamma': hp.uniform('gamma',0.001,1),'probability':hp.choice('probability',[True]),'weight_factor':weight_factor}\n",
    "    xgb_param = {'learning_rate':hp.choice('learning_rate',[0.1]),'max_depth': 5+hp.randint('max_depth',15),'n_estimators':500+hp.randint('n_estimators',2000),'reg_lambda': hp.uniform('reg_lambda',20,100),'gamma': hp.uniform('gamma',0.01,10),'weight_factor':weight_factor}\n",
    "    dnn_param = {'batch_normalization': hp.choice('batch_normalization',[True]),\n",
    "                 'l2_reg': hp.uniform('l2_reg',0.001,5),                            \n",
    "                 'drop_out':hp.uniform('drop_out',0.1,0.8),\n",
    "                 'weight_factor':weight_factor,\n",
    "                 'steps':200+hp.randint('steps',1000),\n",
    "                 'batch_size':hp.choice('batch_size',[30]),\n",
    "                 'scoring':hp.choice('scoring',['precision']),\n",
    "                 }\n",
    "    mlp_param = {'alpha':hp.uniform('alpha',0.001,5),'max_iter':2000+hp.randint('max_iter',1000)}\n",
    "    lsvc_param = {'C': hp.uniform('C',0.1,10),'weight_factor':weight_factor} \n",
    "    if 'LogisticRegression' in methods:\n",
    "        params['LogisticRegression'] = l_param\n",
    "    if 'RandomForestClassifier' in methods:\n",
    "        params['RandomForestClassifier'] = rf_param\n",
    "    if 'SVC' in methods:\n",
    "        params['SVC'] = svc_param\n",
    "    if 'xgbooster' in methods:\n",
    "        params['xgbooster'] = xgb_param\n",
    "    if 'tensor_DNN' in methods:\n",
    "        params['tensor_DNN'] = dnn_param\n",
    "    if 'MLPClassifier' in methods:\n",
    "        params['MLPClassifier'] = mlp_param\n",
    "    if 'LinearSVC' in methods:\n",
    "        params['LinearSVC'] = lsvc_param\n",
    "    return params    \n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "def methods_combination_results(methods,model_probs,test_label):\n",
    "    n = len(methods)\n",
    "    results = {}\n",
    "    for i in range(1,n+1):\n",
    "        iterator = itertools.combinations(methods,i)\n",
    "        for combination in iterator:\n",
    "            key = reduce(lambda x,y: x+'-'+y,combination)\n",
    "            print(key)\n",
    "            test_model_probs = {method:prob for method,prob in model_probs.items() if method in combination}\n",
    "            pred_probs,pred = soft_voting(test_model_probs)\n",
    "            test_score = scores(test_label,pred,pred_probs[:,1])\n",
    "            results[key] = test_score.copy()\n",
    "    return results\n",
    "#---------------------------------------------------------------------\n",
    "def upsampling(train_x,train_label,sample_weights_train,fold=9):\n",
    "    trainx = train_x.copy()\n",
    "    trainx['label'] = train_label\n",
    "    trainx['weight'] = sample_weights_train\n",
    "    up_samples = commons.upSampling(trainx[trainx['label']==1],10)\n",
    "    trainx = trainx.append(up_samples,ignore_index=True).sample(frac=1).reset_index(drop=True)\n",
    "    train_label = trainx['label']\n",
    "    sample_weights_train = trainx['weight']\n",
    "    trainx = trainx.drop(['label','weight'],axis=1)\n",
    "    return trainx,train_label,sample_weights_train\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def downsampling(x,y,sample_weights):\n",
    "    x = x.copy()\n",
    "    x['label'] = y\n",
    "    x['weight'] = sample_weights\n",
    "    pos = x[x['label']==1]\n",
    "    negs = x[x['label']==0].sample(pos.shape[0])\n",
    "    alls = pos.append(negs,ignore_index=True)\n",
    "    label = alls['label']\n",
    "    weights = alls['weight']\n",
    "    return alls.drop(['label','weight'],axis=1),label,weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = str(prediction_commons.tss_start)\n",
    "end = str(prediction_commons.tss_end)\n",
    "home+'data/'+dataset+'all_features'+start+'_'+end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##features selecetd by traditional methods\n",
    "home='/home/ec2-user/CpGPython/'\n",
    "dataset = 'AD_CpG'\n",
    "up_sampling = True;\n",
    "if up_sampling:\n",
    "    wtf_lo = 0.05 if dataset==\"RICHS\" else 0.2\n",
    "    wtf_hi = 0.1 if dataset==\"RICHS\" else 0.3\n",
    "else:\n",
    "    wtf_lo = 1.0/3 if dataset==\"RICHS\" else 1 \n",
    "    wtf_hi = 0.5 if dataset==\"RICHS\" else 1.5\n",
    "    \n",
    "log_dir = home+'logs/'\n",
    "logger = Logger.Logger(log_dir,False).get_logger()\n",
    "with pd.HDFStore(home+'data/'+dataset+'/selected_features','r') as h5s:\n",
    "    train_x =h5s['train_x'] \n",
    "    train_label = h5s['train_label'] \n",
    "    test_x = h5s['test_x'] \n",
    "    test_label = h5s['test_label']\n",
    "    sample_weights_train = h5s['sample_weights_train'] \n",
    "    sample_weights_test = h5s['sample_weights_test']\n",
    "total_x = pd.concat([train_x,test_x],ignore_index=True)\n",
    "total_label = pd.concat([train_label,test_label],ignore_index=True)\n",
    "total_sample_weights = pd.concat([sample_weights_train,sample_weights_test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######model training\n",
    "methods = ['LogisticRegression','xgbooster']\n",
    "params = get_hyperopt_params(methods,wtf_lo=wtf_lo,wtf_hi=wtf_hi)\n",
    "ensemble_hyopt = eh.Ensemble(methods,params)\n",
    "ensemble_hyopt.fit(total_x,total_label,sample_weight=total_sample_weights_train,max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = total_x.columns\n",
    "with pd.HDFStore(home+'data/'+dataset+'/all_features_'+start+'_'+end,'r') as h5s:\n",
    "    wgbs_all_data = h5s['all_features']\n",
    "wgbs_data = wgbs_all_data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = ensemble_hyopt.predict(wgbs_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

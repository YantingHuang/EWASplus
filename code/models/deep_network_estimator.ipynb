{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ec2-user/CpGPython/code/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import Logger\n",
    "from functools import partial\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dnn_model(features,labels,mode,params):\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        training = True\n",
    "    else:\n",
    "        training = False\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        sample_weights = features.pop('sample_weights')\n",
    "        print(sample_weights)\n",
    "    if_batch_norm = params['batch_normalization'] if 'batch_normalization' in params else True\n",
    "    l2_reg = params['l2_reg'] if 'l2_reg' in params else 0\n",
    "    n_classes = params['n_classes'] if 'n_classes' in params else 2\n",
    "    hidden_layers = params['hidden_layers']\n",
    "    dropout_rate = params['dropout'] if 'dropout' in params else 0\n",
    "    activation = tf.nn.elu\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "    dense_layer = partial(tf.layers.dense,kernel_regularizer=regularizer,kernel_initializer=he_init)\n",
    "    dropout = partial(tf.layers.dropout,rate=dropout_rate,training=training)\n",
    "    batch_norm = partial(tf.layers.batch_normalization,training=training,momentum=0.9)\n",
    "    net = tf.feature_column.input_layer(features,params['feature_columns'])\n",
    "    for units in hidden_layers:\n",
    "        net_drop = dropout(net)\n",
    "        \n",
    "        if if_batch_norm:\n",
    "            hidden = dense_layer(net_drop,units)\n",
    "            bn = batch_norm(hidden)\n",
    "            net = activation(bn)\n",
    "        else:\n",
    "            net = dense_layer(net_drop,units,activation=activation)\n",
    "    \n",
    "    logits_before_bn = dense_layer(net,n_classes)\n",
    "    logits = batch_norm(logits_before_bn)\n",
    "    #prediction \n",
    "    predicts = tf.arg_max(logits,1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "                'class_ids':predicts[:,tf.newaxis],\n",
    "                'probabilities': tf.nn.softmax(logits),\n",
    "                'logits': logits,}\n",
    "        return tf.estimator.EstimatorSpec(mode,predictions=predictions)\n",
    "    \n",
    "    ##loss\n",
    "    unweighted_base_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits,name='base_loss')\n",
    "    tf.summary.scalar('unweighted base losses',tf.reduce_mean(unweighted_base_losses))\n",
    "    base_losses = tf.reduce_mean(tf.multiply(tf.cast(sample_weights,dtype=tf.float32),unweighted_base_losses))\n",
    "    tf.summary.scalar('weighted base losses',base_losses)\n",
    "    weight_max = tf.reduce_max(sample_weights)\n",
    "    weight_min = tf.reduce_min(sample_weights)\n",
    "    tf.summary.scalar('max weight',weight_max)\n",
    "    tf.summary.scalar('min weight',weight_min)\n",
    "    reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_losses]+reg_loss,name='loss')\n",
    "    \n",
    "    #evaluation \n",
    "    accuracy = tf.metrics.accuracy(labels=labels,predictions=predicts,name='acc_op')\n",
    "    recall = tf.metrics.recall(labels=labels,predictions=predicts,name='recall_op')\n",
    "    precision = tf.metrics.precision(labels=labels,predictions=predicts,name='precision_op')\n",
    "    auc = tf.metrics.auc(labels,predicts,name='auc_op')\n",
    "    metrics = {'accuracy':accuracy,'recall':recall,'precision':precision,'auc':auc}\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode,loss=base_losses,eval_metric_ops=metrics)\n",
    "    \n",
    "    #training\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(loss,global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode,loss=loss,train_op=train_op)\n",
    "\n",
    "def train_input_fn(data,labels,sample_weights,batch_size):\n",
    "    data = data.copy()\n",
    "    data['sample_weights'] = sample_weights\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data),labels))\n",
    "    shuffle_len = int(len(labels)*2)\n",
    "    return dataset.shuffle(shuffle_len).repeat().batch(batch_size)\n",
    "\n",
    "def eval_input_fn(data,labels,sample_weights,batch_size):\n",
    "    features = dict(data)\n",
    "    if labels is None:\n",
    "        inputs = features\n",
    "    else:\n",
    "        data = data.copy()\n",
    "        data['sample_weights'] = sample_weights\n",
    "        inputs = (dict(data),labels)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    assert batch_size is not None\n",
    "    return dataset.batch(batch_size)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "home='/home/ec2-user/CpGPython/'\n",
    "log_dir = home+'logs/'\n",
    "logger = Logger.Logger(log_dir,False).get_logger()\n",
    "tensorboard_log = home+'tensor_logs/'+datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "##features selecetd by traditional methods\n",
    "with pd.HDFStore(home+'data/selected_features','r') as h5s:\n",
    "    train_x =h5s['train_x'] \n",
    "    train_label = h5s['train_label'] \n",
    "    test_x = h5s['test_x'] \n",
    "    test_label = h5s['test_label']   \n",
    "    sample_weights_train = h5s['sample_weights_train'] \n",
    "    sample_weights_test = h5s['sample_weights_test'] \n",
    "sample_weights_train = np.power(sample_weights_train,1.5)\n",
    "sample_weights_test = np.power(sample_weights_test,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_label = train_label.astype('i8')\n",
    "test_label = test_label.astype('i8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = \".*[+].*\"\n",
    "reg = re.compile(pattern)\n",
    "for key in train_x.keys():\n",
    "    if len(reg.findall(key))>0:\n",
    "        key1 = key.replace('+','plus')\n",
    "        train_x.rename({key:key1},axis=1,inplace=True)\n",
    "        test_x.rename({key:key1},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "for key in train_x.keys():\n",
    "    feature_cols.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_num = train_x.shape[0]\n",
    "params = {'feature_columns':feature_cols,'batch_normalization':True,'l2_reg':0.01,'n_classes':len(train_label.unique()),'hidden_layers':[int(train_num*1.5),int(train_num*1),int(train_num*0.5)],'drop_out':0.5}\n",
    "estimator = tf.estimator.Estimator(model_fn=dnn_model,params=params,model_dir=tensorboard_log)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:176\", shape=(?,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "train_loss = estimator.train(input_fn=lambda:train_input_fn(train_x,train_label,sample_weights_train,30),steps=2000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/CpGPython/tensor_logs/20180409022157'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:176\", shape=(?,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "eval_results = estimator.evaluate(input_fn=lambda:eval_input_fn(test_x,test_label,sample_weights_test,235))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.5, 'precision': 0.0, 'recall': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorings=['precision','recall','auc']\n",
    "{key:val for key,val in eval_results.items() if key in scorings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set scores{'accuracy': 0.5148936, 'auc': 0.48783615, 'loss': 0.88729197, 'precision': 0.08928572, 'recall': 0.45454547, 'global_step': 2000}\n"
     ]
    }
   ],
   "source": [
    "print('Test set scores'+str(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_results = estimator.predict(input_fn=lambda:eval_input_fn(test_x,None,None,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict is 0, expect is 0,Proba is [0.673224  0.3267761]\n",
      "Predict is 0, expect is 0,Proba is [0.8650728  0.13492724]\n",
      "Predict is 0, expect is 0,Proba is [0.8345747  0.16542536]\n",
      "Predict is 0, expect is 0,Proba is [0.6831557  0.31684425]\n",
      "Predict is 0, expect is 0,Proba is [0.88707155 0.11292844]\n",
      "Predict is 0, expect is 0,Proba is [0.5387781 0.4612219]\n",
      "Predict is 0, expect is 0,Proba is [0.8625271  0.13747294]\n",
      "Predict is 0, expect is 0,Proba is [0.98484033 0.01515965]\n",
      "Predict is 0, expect is 0,Proba is [0.8114418  0.18855825]\n",
      "Predict is 0, expect is 1,Proba is [0.68408865 0.31591138]\n",
      "Predict is 0, expect is 0,Proba is [0.6793191 0.3206809]\n",
      "Predict is 0, expect is 0,Proba is [0.7617459  0.23825406]\n",
      "Predict is 0, expect is 0,Proba is [0.84842193 0.1515781 ]\n",
      "Predict is 0, expect is 0,Proba is [0.7113269  0.28867307]\n",
      "Predict is 0, expect is 0,Proba is [0.9219892  0.07801083]\n",
      "Predict is 0, expect is 0,Proba is [0.7232468 0.2767532]\n",
      "Predict is 0, expect is 0,Proba is [0.74165213 0.2583478 ]\n",
      "Predict is 0, expect is 0,Proba is [0.79624754 0.20375249]\n",
      "Predict is 0, expect is 0,Proba is [0.9691831  0.03081697]\n",
      "Predict is 0, expect is 0,Proba is [0.9895662  0.01043378]\n",
      "Predict is 0, expect is 0,Proba is [0.7645466  0.23545341]\n",
      "Predict is 0, expect is 0,Proba is [0.62699145 0.37300846]\n",
      "Predict is 0, expect is 0,Proba is [0.80356294 0.19643706]\n",
      "Predict is 0, expect is 1,Proba is [0.82035315 0.17964691]\n",
      "Predict is 0, expect is 0,Proba is [0.87276816 0.12723179]\n",
      "Predict is 0, expect is 0,Proba is [0.6142474  0.38575262]\n",
      "Predict is 0, expect is 0,Proba is [0.782373   0.21762697]\n",
      "Predict is 0, expect is 0,Proba is [0.6187477  0.38125223]\n",
      "Predict is 0, expect is 0,Proba is [0.874505 0.125495]\n",
      "Predict is 0, expect is 0,Proba is [0.9719177  0.02808234]\n",
      "Predict is 0, expect is 0,Proba is [0.9017216  0.09827843]\n",
      "Predict is 0, expect is 0,Proba is [0.7064573  0.29354265]\n",
      "Predict is 0, expect is 0,Proba is [0.91411275 0.08588728]\n",
      "Predict is 0, expect is 0,Proba is [0.672141 0.327859]\n",
      "Predict is 0, expect is 1,Proba is [0.92466664 0.07533342]\n",
      "Predict is 0, expect is 0,Proba is [0.70980734 0.29019266]\n",
      "Predict is 0, expect is 0,Proba is [0.85211223 0.14788772]\n",
      "Predict is 0, expect is 0,Proba is [0.8138158  0.18618424]\n",
      "Predict is 0, expect is 0,Proba is [0.9392522 0.0607478]\n",
      "Predict is 0, expect is 0,Proba is [0.678124   0.32187605]\n",
      "Predict is 0, expect is 0,Proba is [0.8801913  0.11980866]\n",
      "Predict is 0, expect is 0,Proba is [0.72140956 0.27859047]\n",
      "Predict is 0, expect is 1,Proba is [0.76166064 0.23833935]\n",
      "Predict is 0, expect is 0,Proba is [0.7814149  0.21858507]\n",
      "Predict is 0, expect is 0,Proba is [0.94564366 0.05435635]\n",
      "Predict is 0, expect is 1,Proba is [0.7530246  0.24697542]\n",
      "Predict is 0, expect is 0,Proba is [0.9244814  0.07551868]\n",
      "Predict is 0, expect is 0,Proba is [0.6547532  0.34524673]\n",
      "Predict is 0, expect is 0,Proba is [0.7754566  0.22454342]\n",
      "Predict is 0, expect is 0,Proba is [0.5409959  0.45900413]\n",
      "Predict is 0, expect is 0,Proba is [0.96026486 0.03973516]\n",
      "Predict is 0, expect is 0,Proba is [0.8099801  0.19001992]\n",
      "Predict is 0, expect is 0,Proba is [0.6659659  0.33403403]\n",
      "Predict is 0, expect is 0,Proba is [0.5837103  0.41628972]\n",
      "Predict is 0, expect is 0,Proba is [0.7088489 0.2911511]\n",
      "Predict is 0, expect is 0,Proba is [0.7806911  0.21930888]\n",
      "Predict is 0, expect is 0,Proba is [0.8983315  0.10166846]\n",
      "Predict is 0, expect is 0,Proba is [0.842416   0.15758404]\n",
      "Predict is 0, expect is 0,Proba is [0.6981119 0.3018881]\n",
      "Predict is 0, expect is 0,Proba is [0.60397875 0.39602122]\n",
      "Predict is 0, expect is 0,Proba is [0.8433772  0.15662281]\n",
      "Predict is 0, expect is 0,Proba is [0.9556133  0.04438671]\n",
      "Predict is 0, expect is 0,Proba is [0.909304   0.09069595]\n",
      "Predict is 0, expect is 0,Proba is [0.8346387  0.16536127]\n",
      "Predict is 0, expect is 0,Proba is [0.6072606  0.39273936]\n",
      "Predict is 0, expect is 0,Proba is [0.8619327  0.13806738]\n",
      "Predict is 0, expect is 0,Proba is [0.579369 0.420631]\n",
      "Predict is 0, expect is 0,Proba is [0.81794435 0.18205573]\n",
      "Predict is 0, expect is 0,Proba is [0.6116753  0.38832477]\n",
      "Predict is 0, expect is 0,Proba is [0.958515   0.04148503]\n",
      "Predict is 0, expect is 0,Proba is [0.8732897  0.12671027]\n",
      "Predict is 0, expect is 0,Proba is [0.7526613  0.24733871]\n",
      "Predict is 0, expect is 0,Proba is [0.54689187 0.4531082 ]\n",
      "Predict is 0, expect is 1,Proba is [0.63809335 0.36190665]\n",
      "Predict is 0, expect is 0,Proba is [0.90614283 0.09385718]\n",
      "Predict is 0, expect is 0,Proba is [0.874012 0.125988]\n",
      "Predict is 0, expect is 0,Proba is [0.9850841 0.0149159]\n",
      "Predict is 0, expect is 0,Proba is [0.6110158  0.38898414]\n",
      "Predict is 0, expect is 0,Proba is [0.844032   0.15596801]\n",
      "Predict is 0, expect is 0,Proba is [0.92150646 0.07849349]\n",
      "Predict is 0, expect is 0,Proba is [0.62342966 0.37657028]\n",
      "Predict is 0, expect is 0,Proba is [0.7227999  0.27720013]\n",
      "Predict is 0, expect is 0,Proba is [0.88193494 0.11806507]\n",
      "Predict is 0, expect is 0,Proba is [0.8989429  0.10105713]\n",
      "Predict is 0, expect is 0,Proba is [0.968873   0.03112697]\n",
      "Predict is 0, expect is 0,Proba is [0.69409966 0.30590037]\n",
      "Predict is 0, expect is 0,Proba is [0.60221595 0.39778402]\n",
      "Predict is 0, expect is 0,Proba is [0.75576055 0.24423951]\n",
      "Predict is 0, expect is 0,Proba is [0.5818623 0.4181377]\n",
      "Predict is 0, expect is 1,Proba is [0.6788956 0.3211044]\n",
      "Predict is 0, expect is 0,Proba is [0.7389995  0.26100045]\n",
      "Predict is 0, expect is 0,Proba is [0.7633523 0.2366477]\n",
      "Predict is 0, expect is 1,Proba is [0.76483107 0.23516893]\n",
      "Predict is 0, expect is 0,Proba is [0.95763195 0.04236804]\n",
      "Predict is 0, expect is 1,Proba is [0.8768516  0.12314835]\n",
      "Predict is 0, expect is 0,Proba is [0.9618132  0.03818678]\n",
      "Predict is 0, expect is 0,Proba is [0.75847465 0.24152534]\n",
      "Predict is 0, expect is 0,Proba is [0.7470101  0.25298998]\n",
      "Predict is 0, expect is 0,Proba is [0.80101085 0.19898915]\n",
      "Predict is 0, expect is 0,Proba is [0.89708656 0.10291344]\n",
      "Predict is 0, expect is 1,Proba is [0.85465837 0.14534159]\n",
      "Predict is 0, expect is 0,Proba is [0.608763 0.391237]\n",
      "Predict is 0, expect is 1,Proba is [0.5591617 0.4408383]\n",
      "Predict is 0, expect is 0,Proba is [0.99409497 0.00590501]\n",
      "Predict is 0, expect is 0,Proba is [0.9620568  0.03794322]\n",
      "Predict is 0, expect is 0,Proba is [0.86228913 0.13771093]\n",
      "Predict is 0, expect is 0,Proba is [0.98378664 0.01621337]\n",
      "Predict is 0, expect is 0,Proba is [0.55771327 0.44228667]\n",
      "Predict is 0, expect is 0,Proba is [0.79435813 0.20564182]\n",
      "Predict is 0, expect is 0,Proba is [0.6313946  0.36860538]\n",
      "Predict is 0, expect is 0,Proba is [0.7714566  0.22854342]\n",
      "Predict is 0, expect is 0,Proba is [0.58783406 0.41216597]\n",
      "Predict is 0, expect is 0,Proba is [0.71741635 0.28258365]\n",
      "Predict is 0, expect is 0,Proba is [0.58390516 0.41609484]\n",
      "Predict is 0, expect is 0,Proba is [0.8336086  0.16639133]\n",
      "Predict is 0, expect is 0,Proba is [0.9769612  0.02303879]\n",
      "Predict is 0, expect is 0,Proba is [0.76947856 0.2305215 ]\n",
      "Predict is 0, expect is 0,Proba is [0.59031695 0.40968308]\n",
      "Predict is 0, expect is 0,Proba is [0.8174699  0.18253005]\n",
      "Predict is 0, expect is 0,Proba is [0.5473708 0.4526292]\n",
      "Predict is 0, expect is 0,Proba is [0.68722445 0.31277552]\n",
      "Predict is 0, expect is 0,Proba is [0.87610817 0.12389185]\n",
      "Predict is 0, expect is 0,Proba is [0.66335434 0.3366456 ]\n",
      "Predict is 0, expect is 0,Proba is [0.9068498  0.09315021]\n",
      "Predict is 0, expect is 0,Proba is [0.8727048  0.12729514]\n",
      "Predict is 0, expect is 0,Proba is [0.86032045 0.13967949]\n",
      "Predict is 0, expect is 0,Proba is [0.8306153  0.16938473]\n",
      "Predict is 0, expect is 0,Proba is [0.7252852 0.2747148]\n",
      "Predict is 0, expect is 0,Proba is [0.774485   0.22551505]\n",
      "Predict is 0, expect is 0,Proba is [0.6559654 0.3440346]\n",
      "Predict is 0, expect is 0,Proba is [0.86833596 0.1316641 ]\n",
      "Predict is 0, expect is 0,Proba is [0.6248515  0.37514845]\n",
      "Predict is 0, expect is 1,Proba is [0.7241632  0.27583674]\n",
      "Predict is 0, expect is 0,Proba is [0.8534027  0.14659728]\n",
      "Predict is 0, expect is 0,Proba is [0.9910794  0.00892058]\n",
      "Predict is 0, expect is 0,Proba is [0.7966372  0.20336282]\n",
      "Predict is 0, expect is 0,Proba is [0.7194225  0.28057748]\n",
      "Predict is 0, expect is 0,Proba is [0.60139173 0.39860818]\n",
      "Predict is 0, expect is 0,Proba is [0.5434657  0.45653427]\n",
      "Predict is 0, expect is 0,Proba is [0.6158695  0.38413045]\n",
      "Predict is 0, expect is 0,Proba is [0.6550743 0.3449256]\n",
      "Predict is 0, expect is 0,Proba is [0.65367484 0.3463252 ]\n",
      "Predict is 0, expect is 0,Proba is [0.7775705  0.22242953]\n",
      "Predict is 0, expect is 0,Proba is [0.6308082  0.36919188]\n",
      "Predict is 0, expect is 0,Proba is [0.636926   0.36307403]\n",
      "Predict is 0, expect is 0,Proba is [0.658867 0.341133]\n",
      "Predict is 0, expect is 0,Proba is [0.85260063 0.14739937]\n",
      "Predict is 0, expect is 0,Proba is [0.84677756 0.15322244]\n",
      "Predict is 0, expect is 0,Proba is [0.6691235  0.33087653]\n",
      "Predict is 0, expect is 0,Proba is [0.752895   0.24710494]\n",
      "Predict is 0, expect is 0,Proba is [0.96386856 0.03613137]\n",
      "Predict is 0, expect is 1,Proba is [0.88205224 0.11794774]\n",
      "Predict is 0, expect is 0,Proba is [0.6695436  0.33045638]\n",
      "Predict is 0, expect is 0,Proba is [0.87955916 0.12044089]\n",
      "Predict is 0, expect is 0,Proba is [0.84082866 0.15917133]\n",
      "Predict is 0, expect is 0,Proba is [0.97912 0.02088]\n",
      "Predict is 0, expect is 0,Proba is [0.58344066 0.4165593 ]\n",
      "Predict is 0, expect is 0,Proba is [0.5715243  0.42847562]\n",
      "Predict is 0, expect is 0,Proba is [0.9223379  0.07766208]\n",
      "Predict is 0, expect is 0,Proba is [0.7576172  0.24238278]\n",
      "Predict is 0, expect is 0,Proba is [0.57545704 0.424543  ]\n",
      "Predict is 0, expect is 0,Proba is [0.9117195  0.08828054]\n",
      "Predict is 0, expect is 1,Proba is [0.68873    0.31127003]\n",
      "Predict is 0, expect is 0,Proba is [0.9578954  0.04210461]\n",
      "Predict is 0, expect is 0,Proba is [0.9734553 0.0265447]\n",
      "Predict is 0, expect is 0,Proba is [0.8759333  0.12406676]\n",
      "Predict is 0, expect is 0,Proba is [0.7769591  0.22304088]\n",
      "Predict is 0, expect is 0,Proba is [0.85621816 0.1437819 ]\n",
      "Predict is 0, expect is 0,Proba is [0.6559202  0.34407982]\n",
      "Predict is 0, expect is 0,Proba is [0.55429155 0.44570842]\n",
      "Predict is 0, expect is 0,Proba is [0.98115426 0.01884577]\n",
      "Predict is 0, expect is 0,Proba is [0.98437804 0.01562191]\n",
      "Predict is 0, expect is 0,Proba is [0.6450903  0.35490978]\n",
      "Predict is 0, expect is 0,Proba is [0.7230848  0.27691525]\n",
      "Predict is 0, expect is 0,Proba is [0.7889122  0.21108784]\n",
      "Predict is 0, expect is 0,Proba is [0.988817   0.01118308]\n",
      "Predict is 0, expect is 0,Proba is [0.9014588  0.09854116]\n",
      "Predict is 0, expect is 0,Proba is [0.6670917  0.33290827]\n",
      "Predict is 0, expect is 0,Proba is [0.6952498  0.30475023]\n",
      "Predict is 0, expect is 0,Proba is [0.73272294 0.267277  ]\n",
      "Predict is 0, expect is 0,Proba is [0.7742248  0.22577523]\n",
      "Predict is 0, expect is 0,Proba is [0.5904378 0.4095621]\n",
      "Predict is 0, expect is 0,Proba is [0.7967877  0.20321225]\n",
      "Predict is 0, expect is 0,Proba is [0.7803752  0.21962479]\n",
      "Predict is 0, expect is 0,Proba is [0.6417563  0.35824367]\n",
      "Predict is 0, expect is 0,Proba is [0.6041858  0.39581412]\n",
      "Predict is 0, expect is 0,Proba is [0.7051609  0.29483905]\n",
      "Predict is 0, expect is 0,Proba is [0.8005531 0.1994469]\n",
      "Predict is 0, expect is 0,Proba is [0.7892553  0.21074466]\n",
      "Predict is 0, expect is 1,Proba is [0.7674758  0.23252417]\n",
      "Predict is 0, expect is 0,Proba is [0.8974296  0.10257039]\n",
      "Predict is 0, expect is 0,Proba is [0.78856546 0.21143456]\n",
      "Predict is 0, expect is 0,Proba is [0.77639776 0.22360225]\n",
      "Predict is 0, expect is 0,Proba is [0.6217528 0.3782472]\n",
      "Predict is 0, expect is 0,Proba is [0.68506545 0.31493455]\n",
      "Predict is 0, expect is 0,Proba is [0.93929636 0.06070364]\n",
      "Predict is 0, expect is 1,Proba is [0.6371524 0.3628476]\n",
      "Predict is 0, expect is 0,Proba is [0.86878836 0.13121158]\n",
      "Predict is 0, expect is 0,Proba is [0.7722585  0.22774145]\n",
      "Predict is 0, expect is 0,Proba is [0.9903799  0.00962014]\n",
      "Predict is 0, expect is 0,Proba is [0.93431187 0.06568813]\n",
      "Predict is 0, expect is 1,Proba is [0.9972741  0.00272593]\n",
      "Predict is 0, expect is 0,Proba is [0.80148774 0.19851227]\n",
      "Predict is 0, expect is 0,Proba is [0.9163574 0.0836426]\n",
      "Predict is 0, expect is 0,Proba is [0.69172037 0.30827954]\n",
      "Predict is 0, expect is 0,Proba is [0.6337755  0.36622447]\n",
      "Predict is 0, expect is 0,Proba is [0.9312674  0.06873257]\n",
      "Predict is 0, expect is 0,Proba is [0.558444 0.441556]\n",
      "Predict is 0, expect is 0,Proba is [0.9227628  0.07723713]\n",
      "Predict is 0, expect is 0,Proba is [0.8813776  0.11862238]\n",
      "Predict is 0, expect is 0,Proba is [0.9518958  0.04810423]\n",
      "Predict is 0, expect is 0,Proba is [0.87921566 0.12078434]\n",
      "Predict is 0, expect is 0,Proba is [0.8733274  0.12667266]\n",
      "Predict is 0, expect is 0,Proba is [0.6533076  0.34669247]\n",
      "Predict is 0, expect is 0,Proba is [0.7857551  0.21424492]\n",
      "Predict is 0, expect is 0,Proba is [0.6146002 0.3853998]\n",
      "Predict is 0, expect is 0,Proba is [0.9540215  0.04597853]\n",
      "Predict is 0, expect is 1,Proba is [0.9884411  0.01155895]\n",
      "Predict is 0, expect is 1,Proba is [0.82671916 0.17328084]\n",
      "Predict is 0, expect is 0,Proba is [0.86678016 0.13321984]\n",
      "Predict is 0, expect is 1,Proba is [0.67435706 0.32564297]\n",
      "Predict is 0, expect is 0,Proba is [0.961384   0.03861602]\n",
      "Predict is 0, expect is 0,Proba is [0.75122696 0.24877308]\n",
      "Predict is 0, expect is 1,Proba is [0.9955042  0.00449581]\n",
      "Predict is 0, expect is 0,Proba is [0.8847603  0.11523971]\n",
      "Predict is 0, expect is 0,Proba is [0.6200943  0.37990576]\n",
      "Predict is 0, expect is 0,Proba is [0.8082956  0.19170436]\n",
      "Predict is 0, expect is 0,Proba is [0.73956627 0.2604337 ]\n",
      "Predict is 0, expect is 0,Proba is [0.9092653  0.09073468]\n",
      "Predict is 0, expect is 0,Proba is [0.90503246 0.09496755]\n",
      "Predict is 0, expect is 1,Proba is [0.91780275 0.08219723]\n",
      "Predict is 0, expect is 0,Proba is [0.9745352  0.02546482]\n",
      "Predict is 0, expect is 0,Proba is [0.98746324 0.01253669]\n",
      "Predict is 0, expect is 0,Proba is [0.8845087  0.11549135]\n",
      "Predict is 0, expect is 0,Proba is [0.5904299 0.4095702]\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "for pred_dict,expec in zip(predict_results,test_label):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    prob = pred_dict['probabilities']\n",
    "    probs.extend(prob)\n",
    "    print('Predict is {}, expect is {},Proba is {}'.format(class_id,expec,prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.673224,\n",
       " 0.3267761,\n",
       " 0.8650728,\n",
       " 0.13492724,\n",
       " 0.8345747,\n",
       " 0.16542536,\n",
       " 0.6831557,\n",
       " 0.31684425,\n",
       " 0.88707155,\n",
       " 0.11292844,\n",
       " 0.5387781,\n",
       " 0.4612219,\n",
       " 0.8625271,\n",
       " 0.13747294,\n",
       " 0.98484033,\n",
       " 0.015159647,\n",
       " 0.8114418,\n",
       " 0.18855825,\n",
       " 0.68408865,\n",
       " 0.31591138,\n",
       " 0.6793191,\n",
       " 0.3206809,\n",
       " 0.7617459,\n",
       " 0.23825406,\n",
       " 0.84842193,\n",
       " 0.1515781,\n",
       " 0.7113269,\n",
       " 0.28867307,\n",
       " 0.9219892,\n",
       " 0.078010835,\n",
       " 0.7232468,\n",
       " 0.2767532,\n",
       " 0.74165213,\n",
       " 0.2583478,\n",
       " 0.79624754,\n",
       " 0.20375249,\n",
       " 0.9691831,\n",
       " 0.03081697,\n",
       " 0.9895662,\n",
       " 0.010433776,\n",
       " 0.7645466,\n",
       " 0.23545341,\n",
       " 0.62699145,\n",
       " 0.37300846,\n",
       " 0.80356294,\n",
       " 0.19643706,\n",
       " 0.82035315,\n",
       " 0.17964691,\n",
       " 0.87276816,\n",
       " 0.12723179,\n",
       " 0.6142474,\n",
       " 0.38575262,\n",
       " 0.782373,\n",
       " 0.21762697,\n",
       " 0.6187477,\n",
       " 0.38125223,\n",
       " 0.874505,\n",
       " 0.125495,\n",
       " 0.9719177,\n",
       " 0.028082335,\n",
       " 0.9017216,\n",
       " 0.09827843,\n",
       " 0.7064573,\n",
       " 0.29354265,\n",
       " 0.91411275,\n",
       " 0.085887276,\n",
       " 0.672141,\n",
       " 0.327859,\n",
       " 0.92466664,\n",
       " 0.07533342,\n",
       " 0.70980734,\n",
       " 0.29019266,\n",
       " 0.85211223,\n",
       " 0.14788772,\n",
       " 0.8138158,\n",
       " 0.18618424,\n",
       " 0.9392522,\n",
       " 0.0607478,\n",
       " 0.678124,\n",
       " 0.32187605,\n",
       " 0.8801913,\n",
       " 0.11980866,\n",
       " 0.72140956,\n",
       " 0.27859047,\n",
       " 0.76166064,\n",
       " 0.23833935,\n",
       " 0.7814149,\n",
       " 0.21858507,\n",
       " 0.94564366,\n",
       " 0.054356348,\n",
       " 0.7530246,\n",
       " 0.24697542,\n",
       " 0.9244814,\n",
       " 0.07551868,\n",
       " 0.6547532,\n",
       " 0.34524673,\n",
       " 0.7754566,\n",
       " 0.22454342,\n",
       " 0.5409959,\n",
       " 0.45900413,\n",
       " 0.96026486,\n",
       " 0.039735164,\n",
       " 0.8099801,\n",
       " 0.19001992,\n",
       " 0.6659659,\n",
       " 0.33403403,\n",
       " 0.5837103,\n",
       " 0.41628972,\n",
       " 0.7088489,\n",
       " 0.2911511,\n",
       " 0.7806911,\n",
       " 0.21930888,\n",
       " 0.8983315,\n",
       " 0.10166846,\n",
       " 0.842416,\n",
       " 0.15758404,\n",
       " 0.6981119,\n",
       " 0.3018881,\n",
       " 0.60397875,\n",
       " 0.39602122,\n",
       " 0.8433772,\n",
       " 0.15662281,\n",
       " 0.9556133,\n",
       " 0.04438671,\n",
       " 0.909304,\n",
       " 0.090695955,\n",
       " 0.8346387,\n",
       " 0.16536127,\n",
       " 0.6072606,\n",
       " 0.39273936,\n",
       " 0.8619327,\n",
       " 0.13806738,\n",
       " 0.579369,\n",
       " 0.420631,\n",
       " 0.81794435,\n",
       " 0.18205573,\n",
       " 0.6116753,\n",
       " 0.38832477,\n",
       " 0.958515,\n",
       " 0.04148503,\n",
       " 0.8732897,\n",
       " 0.12671027,\n",
       " 0.7526613,\n",
       " 0.24733871,\n",
       " 0.54689187,\n",
       " 0.4531082,\n",
       " 0.63809335,\n",
       " 0.36190665,\n",
       " 0.90614283,\n",
       " 0.09385718,\n",
       " 0.874012,\n",
       " 0.125988,\n",
       " 0.9850841,\n",
       " 0.014915904,\n",
       " 0.6110158,\n",
       " 0.38898414,\n",
       " 0.844032,\n",
       " 0.15596801,\n",
       " 0.92150646,\n",
       " 0.07849349,\n",
       " 0.62342966,\n",
       " 0.37657028,\n",
       " 0.7227999,\n",
       " 0.27720013,\n",
       " 0.88193494,\n",
       " 0.11806507,\n",
       " 0.8989429,\n",
       " 0.10105713,\n",
       " 0.968873,\n",
       " 0.031126967,\n",
       " 0.69409966,\n",
       " 0.30590037,\n",
       " 0.60221595,\n",
       " 0.39778402,\n",
       " 0.75576055,\n",
       " 0.24423951,\n",
       " 0.5818623,\n",
       " 0.4181377,\n",
       " 0.6788956,\n",
       " 0.3211044,\n",
       " 0.7389995,\n",
       " 0.26100045,\n",
       " 0.7633523,\n",
       " 0.2366477,\n",
       " 0.76483107,\n",
       " 0.23516893,\n",
       " 0.95763195,\n",
       " 0.042368043,\n",
       " 0.8768516,\n",
       " 0.12314835,\n",
       " 0.9618132,\n",
       " 0.038186785,\n",
       " 0.75847465,\n",
       " 0.24152534,\n",
       " 0.7470101,\n",
       " 0.25298998,\n",
       " 0.80101085,\n",
       " 0.19898915,\n",
       " 0.89708656,\n",
       " 0.10291344,\n",
       " 0.85465837,\n",
       " 0.14534159,\n",
       " 0.608763,\n",
       " 0.391237,\n",
       " 0.5591617,\n",
       " 0.4408383,\n",
       " 0.99409497,\n",
       " 0.005905014,\n",
       " 0.9620568,\n",
       " 0.03794322,\n",
       " 0.86228913,\n",
       " 0.13771093,\n",
       " 0.98378664,\n",
       " 0.016213372,\n",
       " 0.55771327,\n",
       " 0.44228667,\n",
       " 0.79435813,\n",
       " 0.20564182,\n",
       " 0.6313946,\n",
       " 0.36860538,\n",
       " 0.7714566,\n",
       " 0.22854342,\n",
       " 0.58783406,\n",
       " 0.41216597,\n",
       " 0.71741635,\n",
       " 0.28258365,\n",
       " 0.58390516,\n",
       " 0.41609484,\n",
       " 0.8336086,\n",
       " 0.16639133,\n",
       " 0.9769612,\n",
       " 0.023038788,\n",
       " 0.76947856,\n",
       " 0.2305215,\n",
       " 0.59031695,\n",
       " 0.40968308,\n",
       " 0.8174699,\n",
       " 0.18253005,\n",
       " 0.5473708,\n",
       " 0.4526292,\n",
       " 0.68722445,\n",
       " 0.31277552,\n",
       " 0.87610817,\n",
       " 0.123891845,\n",
       " 0.66335434,\n",
       " 0.3366456,\n",
       " 0.9068498,\n",
       " 0.093150206,\n",
       " 0.8727048,\n",
       " 0.12729514,\n",
       " 0.86032045,\n",
       " 0.13967949,\n",
       " 0.8306153,\n",
       " 0.16938473,\n",
       " 0.7252852,\n",
       " 0.2747148,\n",
       " 0.774485,\n",
       " 0.22551505,\n",
       " 0.6559654,\n",
       " 0.3440346,\n",
       " 0.86833596,\n",
       " 0.1316641,\n",
       " 0.6248515,\n",
       " 0.37514845,\n",
       " 0.7241632,\n",
       " 0.27583674,\n",
       " 0.8534027,\n",
       " 0.14659728,\n",
       " 0.9910794,\n",
       " 0.008920582,\n",
       " 0.7966372,\n",
       " 0.20336282,\n",
       " 0.7194225,\n",
       " 0.28057748,\n",
       " 0.60139173,\n",
       " 0.39860818,\n",
       " 0.5434657,\n",
       " 0.45653427,\n",
       " 0.6158695,\n",
       " 0.38413045,\n",
       " 0.6550743,\n",
       " 0.3449256,\n",
       " 0.65367484,\n",
       " 0.3463252,\n",
       " 0.7775705,\n",
       " 0.22242953,\n",
       " 0.6308082,\n",
       " 0.36919188,\n",
       " 0.636926,\n",
       " 0.36307403,\n",
       " 0.658867,\n",
       " 0.341133,\n",
       " 0.85260063,\n",
       " 0.14739937,\n",
       " 0.84677756,\n",
       " 0.15322244,\n",
       " 0.6691235,\n",
       " 0.33087653,\n",
       " 0.752895,\n",
       " 0.24710494,\n",
       " 0.96386856,\n",
       " 0.03613137,\n",
       " 0.88205224,\n",
       " 0.11794774,\n",
       " 0.6695436,\n",
       " 0.33045638,\n",
       " 0.87955916,\n",
       " 0.12044089,\n",
       " 0.84082866,\n",
       " 0.15917133,\n",
       " 0.97912,\n",
       " 0.020879995,\n",
       " 0.58344066,\n",
       " 0.4165593,\n",
       " 0.5715243,\n",
       " 0.42847562,\n",
       " 0.9223379,\n",
       " 0.07766208,\n",
       " 0.7576172,\n",
       " 0.24238278,\n",
       " 0.57545704,\n",
       " 0.424543,\n",
       " 0.9117195,\n",
       " 0.08828054,\n",
       " 0.68873,\n",
       " 0.31127003,\n",
       " 0.9578954,\n",
       " 0.042104613,\n",
       " 0.9734553,\n",
       " 0.026544696,\n",
       " 0.8759333,\n",
       " 0.124066755,\n",
       " 0.7769591,\n",
       " 0.22304088,\n",
       " 0.85621816,\n",
       " 0.1437819,\n",
       " 0.6559202,\n",
       " 0.34407982,\n",
       " 0.55429155,\n",
       " 0.44570842,\n",
       " 0.98115426,\n",
       " 0.018845774,\n",
       " 0.98437804,\n",
       " 0.015621914,\n",
       " 0.6450903,\n",
       " 0.35490978,\n",
       " 0.7230848,\n",
       " 0.27691525,\n",
       " 0.7889122,\n",
       " 0.21108784,\n",
       " 0.988817,\n",
       " 0.011183081,\n",
       " 0.9014588,\n",
       " 0.098541155,\n",
       " 0.6670917,\n",
       " 0.33290827,\n",
       " 0.6952498,\n",
       " 0.30475023,\n",
       " 0.73272294,\n",
       " 0.267277,\n",
       " 0.7742248,\n",
       " 0.22577523,\n",
       " 0.5904378,\n",
       " 0.4095621,\n",
       " 0.7967877,\n",
       " 0.20321225,\n",
       " 0.7803752,\n",
       " 0.21962479,\n",
       " 0.6417563,\n",
       " 0.35824367,\n",
       " 0.6041858,\n",
       " 0.39581412,\n",
       " 0.7051609,\n",
       " 0.29483905,\n",
       " 0.8005531,\n",
       " 0.1994469,\n",
       " 0.7892553,\n",
       " 0.21074466,\n",
       " 0.7674758,\n",
       " 0.23252417,\n",
       " 0.8974296,\n",
       " 0.10257039,\n",
       " 0.78856546,\n",
       " 0.21143456,\n",
       " 0.77639776,\n",
       " 0.22360225,\n",
       " 0.6217528,\n",
       " 0.3782472,\n",
       " 0.68506545,\n",
       " 0.31493455,\n",
       " 0.93929636,\n",
       " 0.06070364,\n",
       " 0.6371524,\n",
       " 0.3628476,\n",
       " 0.86878836,\n",
       " 0.13121158,\n",
       " 0.7722585,\n",
       " 0.22774145,\n",
       " 0.9903799,\n",
       " 0.009620142,\n",
       " 0.93431187,\n",
       " 0.06568813,\n",
       " 0.9972741,\n",
       " 0.0027259276,\n",
       " 0.80148774,\n",
       " 0.19851227,\n",
       " 0.9163574,\n",
       " 0.0836426,\n",
       " 0.69172037,\n",
       " 0.30827954,\n",
       " 0.6337755,\n",
       " 0.36622447,\n",
       " 0.9312674,\n",
       " 0.06873257,\n",
       " 0.558444,\n",
       " 0.441556,\n",
       " 0.9227628,\n",
       " 0.07723713,\n",
       " 0.8813776,\n",
       " 0.118622385,\n",
       " 0.9518958,\n",
       " 0.048104227,\n",
       " 0.87921566,\n",
       " 0.12078434,\n",
       " 0.8733274,\n",
       " 0.12667266,\n",
       " 0.6533076,\n",
       " 0.34669247,\n",
       " 0.7857551,\n",
       " 0.21424492,\n",
       " 0.6146002,\n",
       " 0.3853998,\n",
       " 0.9540215,\n",
       " 0.045978528,\n",
       " 0.9884411,\n",
       " 0.011558951,\n",
       " 0.82671916,\n",
       " 0.17328084,\n",
       " 0.86678016,\n",
       " 0.13321984,\n",
       " 0.67435706,\n",
       " 0.32564297,\n",
       " 0.961384,\n",
       " 0.038616024,\n",
       " 0.75122696,\n",
       " 0.24877308,\n",
       " 0.9955042,\n",
       " 0.0044958075,\n",
       " 0.8847603,\n",
       " 0.11523971,\n",
       " 0.6200943,\n",
       " 0.37990576,\n",
       " 0.8082956,\n",
       " 0.19170436,\n",
       " 0.73956627,\n",
       " 0.2604337,\n",
       " 0.9092653,\n",
       " 0.090734676,\n",
       " 0.90503246,\n",
       " 0.09496755,\n",
       " 0.91780275,\n",
       " 0.082197234,\n",
       " 0.9745352,\n",
       " 0.025464818,\n",
       " 0.98746324,\n",
       " 0.012536688,\n",
       " 0.8845087,\n",
       " 0.11549135,\n",
       " 0.5904299,\n",
       " 0.4095702]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
